# ANALYSE D√âTAILL√âE DU FLUX DE TRANSCRIPTION PURE - APPLICATION PILOT

> **P√©rim√®tre** : Transcription pure (images ‚Üí JSON) **SANS** importation en base de donn√©es
>
> **Date** : 2025-12-20
>
> **Objectif** : Analyser et optimiser le flux de transcription OCR batch avec Gemini

---

## TABLE DES MATI√àRES

[TOC]

---

## SYNTH√àSE EX√âCUTIVE

Le flux de transcription OCR batch dans l'application pilot traite les images √† travers une t√¢che Celery asynchrone. Le flux actuel fonctionne mais pr√©sente **plusieurs probl√®mes critiques** :

### Probl√®mes identifi√©s

| Priorit√© | Probl√®me | Impact |
|----------|----------|--------|
| üî¥ CRITIQUE | Import timezone manquant | **Application crash** |
| üî¥ CRITIQUE | TranscriptionOCR.fiche non nullable | **Impossible de cr√©er TranscriptionOCR sans fiche** |
| üî¥ CRITIQUE | Pas de d√©tection automatique du prompt | **Anciennes fiches mal transcrites** |
| üî¥ CRITIQUE | Pas de retry sur erreurs API | **Images perdues sur erreur r√©seau** |
| üî¥ CRITIQUE | Pas de rate limiting | **Risque de ban Google API** |
| üü° HAUTE | Pas de timeout API | **Gelage du batch possible** |
| üü° HAUTE | Validation JSON insuffisante | **Erreurs de parsing** |
| üü¢ MOYENNE | Arborescence JSON trop profonde | **Maintenance difficile** |
| üü¢ MOYENNE | update_state() trop fr√©quent | **Surcharge Redis** |
| üîµ BASSE | sessionStorage pour param√®tres | **Perte de donn√©es possible** |

### Quick Wins recommand√©s

1. **Import timezone** (1 min) ‚Üí √âvite crash
2. **Fiche nullable** (10 min + migration) ‚Üí Permet cr√©ation TranscriptionOCR
3. **D√©tection prompt** (30 min) ‚Üí Am√©liore qualit√© transcription
4. **Retry avec backoff** (1h) ‚Üí Robustesse r√©seau
5. **Rate limiting** (30 min) ‚Üí √âvite ban API

**Total estim√©** : 2h15 pour corriger les 5 probl√®mes critiques

---

## 1. D√âTECTION DU TYPE DE FICHE ET S√âLECTION DU PROMPT

### 1.1 √âtat actuel

**D√©tection du type de fiche** (`pilot/tasks.py:86-110`)

```python
def _determiner_type_fiche_et_traitement(chemin_relatif: str) -> tuple[str, str]:
    """
    D√©termine le type de fiche et de traitement √† partir du chemin.

    Args:
        chemin_relatif: Chemin comme "Ancienne_fiche/Traitement_1"

    Returns:
        (type_fiche, type_traitement)
    """
    parts = chemin_relatif.split(os.sep)
    type_fiche = "Inconnu"
    type_traitement = "Inconnu"

    if len(parts) >= 1:
        type_fiche = parts[0]  # Ex: "Ancienne_fiche"
    if len(parts) >= 2:
        type_traitement = parts[1]  # Ex: "Traitement_1"

    return type_fiche, type_traitement
```

**Chargement du prompt** (`pilot/tasks.py:382-391`)

```python
# ‚ùå PROBL√àME : Toujours le m√™me prompt, quelle que soit la fiche
prompt_path = os.path.join(
    settings.BASE_DIR, 'observations', 'json_rep', 'prompt_gemini_transcription.txt'
)
try:
    with open(prompt_path, encoding='utf-8') as f:
        prompt = f.read()
except Exception as e:
    logger.error(f"Erreur lors du chargement du prompt: {str(e)}")
    return {'status': 'ERROR', 'error': f"Erreur lors du chargement du prompt: {str(e)}"}
```

### 1.2 Prompts disponibles

Deux prompts existent dans `observations/json_rep/` :

#### `prompt_gemini_transcription.txt` (Standard)
- **Usage** : Fiches modernes standard
- **Format** : Tableau au recto, informations structur√©es
- **Taille** : 52 lignes

#### `prompt_gemini_transcription_Ancienne_Fiche.txt` (Archives)
- **Usage** : Fiches ann√©es 70/80
- **Particularit√©s** :
  - Ann√©e √©crite **VERTICALEMENT** en marge droite
  - Feuille IGN en haut √† droite
  - Cases √† cocher pour bilan (Succ√®s/√âchec)
  - Tableau de donn√©es sur le **VERSO uniquement**
  - Normalisation ann√©es (77 ‚Üí 1977)
- **Taille** : 91 lignes

### 1.3 Probl√®mes identifi√©s

| Probl√®me | Severity | Impact |
|----------|----------|--------|
| Pas de d√©tection automatique du prompt | üî¥ CRITIQUE | Anciennes fiches transcrites avec mauvais prompt = erreurs structurelles |
| Type fiche d√©tect√© mais non utilis√© | üü° HAUTE | La logique existe (`_determiner_type_fiche_et_traitement`) mais inutilis√©e |
| Pas de fallback | üü¢ MOYENNE | Erreur non gracieuse si prompt inexistant |
| Pas de logging de s√©lection | üü¢ MOYENNE | Impossible de tracer quel prompt utilis√© |

### 1.4 Solution propos√©e

#### Fonction de chargement automatique

**Cr√©er dans `pilot/tasks.py`** (apr√®s `_determiner_type_fiche_et_traitement`) :

```python
def _charger_prompt_selon_type_fiche(chemin_relatif: str) -> str:
    """
    Charge le bon prompt selon le type de fiche d√©tect√© dans le chemin.

    R√®gle de d√©tection :
    - Si le chemin contient "ancien" ou "Ancien" ‚Üí prompt anciennes fiches
    - Sinon ‚Üí prompt standard

    Args:
        chemin_relatif: Chemin du r√©pertoire (ex: "Ancienne_fiche/Traitement_1")

    Returns:
        Contenu du prompt en string

    Raises:
        ValueError: Si le prompt n'est pas trouv√©

    Example:
        >>> _charger_prompt_selon_type_fiche("Ancienne_fiche/Sans_traitement")
        # Retourne le contenu de prompt_gemini_transcription_Ancienne_Fiche.txt
    """
    type_fiche, _ = _determiner_type_fiche_et_traitement(chemin_relatif)

    # D√©terminer quel prompt utiliser (insensible √† la casse)
    if 'ancien' in type_fiche.lower():
        prompt_filename = 'prompt_gemini_transcription_Ancienne_Fiche.txt'
        logger.info(f"üìÑ Prompt ANCIENNES FICHES s√©lectionn√© pour: {type_fiche}")
    else:
        prompt_filename = 'prompt_gemini_transcription.txt'
        logger.info(f"üìÑ Prompt STANDARD s√©lectionn√© pour: {type_fiche}")

    prompt_path = os.path.join(
        settings.BASE_DIR, 'observations', 'json_rep', prompt_filename
    )

    try:
        with open(prompt_path, encoding='utf-8') as f:
            prompt_content = f.read()
            logger.debug(f"‚úì Prompt charg√©: {prompt_filename} ({len(prompt_content)} chars)")
            return prompt_content
    except FileNotFoundError as e:
        logger.error(f"‚ùå Prompt introuvable: {prompt_path}")
        raise ValueError(f"Prompt {prompt_filename} non trouv√© dans observations/json_rep/") from e
```

#### Int√©gration dans la t√¢che principale

**Modifier `process_batch_transcription_task()`** :

**AVANT** (lignes 382-391) - **√Ä SUPPRIMER** :
```python
# Charger le prompt
prompt_path = os.path.join(
    settings.BASE_DIR, 'observations', 'json_rep', 'prompt_gemini_transcription.txt'
)
try:
    with open(prompt_path, encoding='utf-8') as f:
        prompt = f.read()
except Exception as e:
    logger.error(f"Erreur lors du chargement du prompt: {str(e)}")
    return {'status': 'ERROR', 'error': f"Erreur lors du chargement du prompt: {str(e)}"}
```

**APR√àS** (dans la boucle des r√©pertoires, apr√®s ligne 465) :

```python
# Boucle sur les r√©pertoires
for dir_index, dir_info in enumerate(directories):
    dir_path_relatif = dir_info['path']
    dir_name = dir_info['name']

    logger.info(f"üìÅ Traitement du r√©pertoire {dir_index + 1}/{len(directories)}: {dir_path_relatif}")

    # ‚ú® NOUVEAU : Charger le prompt appropri√© selon le type de fiche
    try:
        prompt = _charger_prompt_selon_type_fiche(dir_path_relatif)
    except ValueError as e:
        logger.error(f"‚ùå Erreur chargement prompt pour {dir_path_relatif}: {e}")
        all_results.append({
            'directory': dir_path_relatif,
            'modele_ocr': modele_ocr,
            'status': 'error',
            'error': f"Prompt introuvable: {str(e)}",
            'files': [],
        })
        continue  # Passer au r√©pertoire suivant

    # D√©terminer le type de fiche et de traitement
    type_fiche, type_traitement = _determiner_type_fiche_et_traitement(dir_path_relatif)

    # ... reste du code
```

### 1.5 Tests recommand√©s

```python
# test_pilot_tasks.py

def test_charger_prompt_ancienne_fiche():
    """V√©rifie que les anciennes fiches utilisent le bon prompt"""
    prompt = _charger_prompt_selon_type_fiche("Ancienne_fiche/Sans_traitement")
    assert "VERTICALEMENT" in prompt
    assert "ann√©es 70" in prompt.lower()

def test_charger_prompt_standard():
    """V√©rifie que les nouvelles fiches utilisent le prompt standard"""
    prompt = _charger_prompt_selon_type_fiche("Nouvelle_fiche/Traitement_1")
    assert "VERTICALEMENT" not in prompt

def test_charger_prompt_case_insensitive():
    """V√©rifie que la d√©tection est insensible √† la casse"""
    prompt1 = _charger_prompt_selon_type_fiche("ANCIENNE_fiche/test")
    prompt2 = _charger_prompt_selon_type_fiche("ancienne_FICHE/test")
    assert prompt1 == prompt2
```

### 1.6 Priorit√©

**üî¥ PRIORIT√â CRITIQUE** - Impact direct sur la qualit√© des transcriptions

---

## 2. ORGANISATION DES FICHIERS JSON R√âSULTATS

### 2.1 √âtat actuel

**Structure r√©elle** (`pilot/tasks.py:461, 544-545`)

```
media/
‚îî‚îÄ‚îÄ transcription_results/
    ‚îî‚îÄ‚îÄ {dir_path_relatif}/           # Ex: Ancienne_fiche/Sans_traitement
        ‚îî‚îÄ‚îÄ {modele_ocr}/              # Ex: gemini_2_flash
            ‚îú‚îÄ‚îÄ {image_name}_result.json
            ‚îî‚îÄ‚îÄ {image_name}_raw.json  # Si erreur d√©tect√©e
```

**Exemple concret** :
```
media/transcription_results/
‚îú‚îÄ‚îÄ Ancienne_fiche/
‚îÇ   ‚îî‚îÄ‚îÄ Sans_traitement/
‚îÇ       ‚îú‚îÄ‚îÄ gemini_2_flash/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ scan_001_result.json
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ scan_001_raw.json
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ scan_002_result.json
‚îÇ       ‚îî‚îÄ‚îÄ gemini_1.5_pro/
‚îÇ           ‚îú‚îÄ‚îÄ scan_001_result.json
‚îÇ           ‚îî‚îÄ‚îÄ scan_002_result.json
‚îî‚îÄ‚îÄ Nouvelle_fiche/
    ‚îî‚îÄ‚îÄ Traitement_1/
        ‚îî‚îÄ‚îÄ gemini_2_flash/
            ‚îî‚îÄ‚îÄ scan_050_result.json
```

### 2.2 Probl√®mes identifi√©s

| Probl√®me | Severity | Impact |
|----------|----------|--------|
| Mod√®le dans le chemin | üü¢ MOYENNE | Arborescence profonde (4 niveaux), instable si mod√®les renomm√©s |
| Pas de m√©tadonn√©es | üü¢ MOYENNE | Impossible de savoir : date, dur√©e, mod√®le utilis√© |
| Pas d'horodatage | üîµ BASSE | Impossible de distinguer 2 ex√©cutions du m√™me batch |
| Pas d'index global | üîµ BASSE | Difficile de retrouver tous les r√©sultats d'un batch |

### 2.3 Solutions propos√©es

#### Solution 1 : Ajouter m√©tadonn√©es en en-t√™te JSON (RECOMMAND√âE)

**Format du fichier JSON avec m√©tadonn√©es** :

```json
{
  "_metadata": {
    "date_transcription": "2025-01-20T14:30:52+01:00",
    "modele_ocr": "gemini_2_flash",
    "duree_secondes": 2.34,
    "type_image": "brute",
    "type_fiche": "Ancienne_fiche",
    "type_traitement": "Sans_traitement",
    "version_prompt": "ancienne",
    "image_source": "scan_001.jpg",
    "chemin_image": "Ancienne_fiche/Sans_traitement/scan_001.jpg",
    "transcription_ocr_id": 12345
  },
  "informations_generales": {
    "n_fiche": "001",
    "observateur": "Jean Dupont",
    ...
  },
  "nid": { ... },
  "localisation": { ... },
  ...
}
```

**Code pour impl√©menter** (dans la boucle image, remplacer lignes 542-548) :

```python
# Construire le JSON final avec m√©tadonn√©es
json_data_with_metadata = {
    "_metadata": {
        "date_transcription": timezone.now().isoformat(),
        "modele_ocr": modele_ocr,
        "duree_secondes": round(duration, 2),
        "type_image": type_image,
        "type_fiche": type_fiche,
        "type_traitement": type_traitement,
        "version_prompt": "ancienne" if "ancien" in type_fiche.lower() else "standard",
        "image_source": img_file,
        "chemin_image": img_path_relatif,
        "transcription_ocr_id": transcription_ocr.pk if transcription_ocr else None,
    },
    **json_data  # Fusionner les donn√©es de transcription
}

# Enregistrement du JSON final
with open(json_path_complet, 'w', encoding='utf-8') as f:
    json.dump(json_data_with_metadata, f, indent=2, ensure_ascii=False)

logger.info(f"‚úì JSON sauvegard√© avec m√©tadonn√©es: {json_path_relatif}")
```

#### Solution 2 : Simplifier l'arborescence (Optionnel)

**Nouvelle structure plus plate** :

```
media/transcription_results/
‚îî‚îÄ‚îÄ {type_fiche}/
    ‚îî‚îÄ‚îÄ {type_traitement}/
        ‚îî‚îÄ‚îÄ {image_name}_{modele}_{timestamp}.json
```

**Avantages** :
- 3 niveaux au lieu de 4
- Mod√®le dans le nom (pas dans le chemin)
- Timestamp pour distinguer les ex√©cutions

**Inconv√©nient** : Tous les mod√®les m√©lang√©s dans le m√™me dossier

### 2.4 Priorit√©

**üü¢ PRIORIT√â MOYENNE** - Am√©lioration de tra√ßabilit√© et maintenance

---

## 3. BOUCLES DE TRAITEMENT ET OPTIMISATION

### 3.1 √âtat actuel

**Structure des boucles** (`pilot/tasks.py:429-632`)

```python
# Boucle 1 : Pour chaque mod√®le OCR
for modele_index, modele_ocr in enumerate(modeles_ocr):
    modele_api = modeles_mapping.get(modele_ocr)
    model = genai.GenerativeModel(modele_api)  # Initialisation du mod√®le

    # Boucle 2 : Pour chaque r√©pertoire
    for dir_index, dir_info in enumerate(directories):

        # Boucle 3 : Pour chaque image
        for img_file in image_files:
            # Traitement (40s par image en moyenne)
            response = model.generate_content([prompt, image])
            # ...

            # ‚ùå PROBL√àME : update_state() √† CHAQUE image
            self.update_state(state='PROGRESS', meta={...})
```

**Calcul de progression** (`pilot/tasks.py:399-411`)

```python
# Total images = somme des images par r√©pertoire √ó nombre de mod√®les
total_images = images_par_repertoire * len(modeles_ocr)
```

### 3.2 Probl√®mes identifi√©s

| Probl√®me | Type | Severity | Impact |
|----------|------|----------|--------|
| Ex√©cution 100% s√©quentielle | Performance | üü° HAUTE | 600 images √ó 40s = **6h40** de traitement |
| Pas de retry sur erreur r√©seau | Robustesse | üî¥ CRITIQUE | Une erreur API = image perdue d√©finitivement |
| Pas de timeout | Robustesse | üü° HAUTE | Un appel gel√© = tout le batch gel√© |
| Pas de rate limiting | Robustesse | üî¥ CRITIQUE | Risque de ban Google API (quota d√©pass√©) |
| update_state() trop fr√©quent | Performance | üü¢ MOYENNE | 600 √©critures Redis = surcharge |
| Pas de gestion m√©moire | Performance | üîµ BASSE | Images PIL non ferm√©es explicitement |

### 3.3 Solutions propos√©es

#### Solution 1 : Retry avec exponential backoff (CRITIQUE)

**Cr√©er une fonction utilitaire** dans `pilot/tasks.py` :

```python
import time
from functools import wraps

def retry_with_backoff(max_retries=3, initial_delay=2, max_delay=16):
    """
    D√©corateur pour retry avec exponential backoff.

    D√©lais progressifs : 2s ‚Üí 4s ‚Üí 8s ‚Üí 16s (max)

    Args:
        max_retries: Nombre maximum de tentatives (d√©faut: 3)
        initial_delay: D√©lai initial en secondes (d√©faut: 2)
        max_delay: D√©lai maximum en secondes (d√©faut: 16)

    Returns:
        D√©corateur de fonction

    Example:
        @retry_with_backoff(max_retries=3)
        def call_api():
            # Code qui peut √©chouer
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            delay = initial_delay
            last_error = None

            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_error = e
                    if attempt < max_retries - 1:
                        logger.warning(
                            f"‚ö†Ô∏è Tentative {attempt + 1}/{max_retries} √©chou√©e pour {func.__name__}: {str(e)}. "
                            f"Retry dans {delay}s..."
                        )
                        time.sleep(delay)
                        delay = min(delay * 2, max_delay)  # Exponential backoff
                    else:
                        logger.error(
                            f"‚ùå Toutes les tentatives √©chou√©es pour {func.__name__} apr√®s {max_retries} essais"
                        )

            raise last_error
        return wrapper
    return decorator
```

**Utilisation** :

```python
@retry_with_backoff(max_retries=3, initial_delay=2)
def call_gemini_api(model, prompt, image_path):
    """Appel API Gemini avec retry automatique"""
    image = Image.open(image_path)
    try:
        response = model.generate_content([prompt, image])
        return response.text.encode('utf-8').decode('utf-8')
    finally:
        image.close()  # Lib√©rer la m√©moire
```

**Int√©gration dans la boucle** (remplacer lignes 507-526) :

```python
try:
    # Appel API avec retry automatique
    text_response = call_gemini_api(model, prompt, img_path_complet)

    # Nettoyage markdown
    if text_response.startswith("```json"):
        text_response = text_response[7:].strip()
        if text_response.endswith("```"):
            text_response = text_response[:-3].strip()

    # Parsing JSON
    json_data = json.loads(text_response)

except Exception as e:
    logger.error(f"‚ùå √âchec d√©finitif pour {img_file} apr√®s retries: {str(e)}")
    file_result = {
        'filename': img_file,
        'status': 'error',
        'error': str(e),
        'duration': round(time.time() - file_start, 2),
    }
    total_errors += 1
    continue  # Passer √† l'image suivante
```

#### Solution 2 : Rate limiting (CRITIQUE)

**Ajouter au d√©but de `process_batch_transcription_task()`** :

```python
# Configuration rate limiting pour Google Gemini API
GEMINI_REQUESTS_PER_MINUTE = 60  # Limite Google
MIN_DELAY_BETWEEN_REQUESTS = 60.0 / GEMINI_REQUESTS_PER_MINUTE  # 1 req/sec

last_request_time = time.time()

def apply_rate_limit():
    """Applique un d√©lai minimum entre les requ√™tes API"""
    global last_request_time

    now = time.time()
    elapsed = now - last_request_time

    if elapsed < MIN_DELAY_BETWEEN_REQUESTS:
        delay = MIN_DELAY_BETWEEN_REQUESTS - elapsed
        logger.debug(f"‚è±Ô∏è Rate limit: attente de {delay:.2f}s")
        time.sleep(delay)

    last_request_time = time.time()
```

**Utilisation dans la boucle image** (avant l'appel API) :

```python
# Respecter le rate limiting
apply_rate_limit()

# Appel API
text_response = call_gemini_api(model, prompt, img_path_complet)
```

#### Solution 3 : Timeout (HAUTE)

**Ajouter timeout √† l'appel API** :

```python
@retry_with_backoff(max_retries=3)
def call_gemini_api(model, prompt, image_path, timeout=120):
    """
    Appel API Gemini avec timeout.

    Args:
        timeout: Timeout en secondes (d√©faut: 120s = 2 minutes)
    """
    image = Image.open(image_path)
    try:
        # Gemini SDK ne supporte pas timeout natif, utiliser threading
        import threading

        result = [None]
        exception = [None]

        def api_call():
            try:
                response = model.generate_content([prompt, image])
                result[0] = response.text.encode('utf-8').decode('utf-8')
            except Exception as e:
                exception[0] = e

        thread = threading.Thread(target=api_call)
        thread.daemon = True
        thread.start()
        thread.join(timeout=timeout)

        if thread.is_alive():
            raise TimeoutError(f"API call exceeded {timeout}s timeout")

        if exception[0]:
            raise exception[0]

        return result[0]

    finally:
        image.close()
```

#### Solution 4 : Optimiser update_state (MOYENNE)

**R√©duire la fr√©quence des updates** :

```python
# Au d√©but de la t√¢che
UPDATE_PROGRESS_EVERY_N_IMAGES = 5  # Mettre √† jour tous les 5 fichiers

# Dans la boucle image
if processed_count % UPDATE_PROGRESS_EVERY_N_IMAGES == 0 or processed_count == total_images:
    self.update_state(
        state='PROGRESS',
        meta={
            'processed': processed_count,
            'total': total_images,
            'current_file': img_file,
            'current_directory': dir_path_relatif,
            'current_model': modele_ocr,
            'percent': int((processed_count / total_images) * 100),
        }
    )
```

### 3.4 Priorit√© par solution

| Solution | Priorit√© | Effort | Impact |
|----------|----------|--------|--------|
| Retry + backoff | üî¥ CRITIQUE | 1h | √âvite perte d'images |
| Rate limiting | üî¥ CRITIQUE | 30 min | √âvite ban API |
| Timeout | üü° HAUTE | 30 min | √âvite gelage |
| Optimiser update_state | üü¢ MOYENNE | 15 min | Am√©liore performance |

---

## 4. GESTION DES ERREURS DE TRANSCRIPTION

### 4.1 √âtat actuel

**Flux de traitement** (`pilot/tasks.py:507-619`)

```python
try:
    # 1. Ouverture image
    image = Image.open(img_path_complet)

    # 2. Appel API (‚ùå PAS DE RETRY, PAS DE TIMEOUT)
    response = model.generate_content([prompt, image])
    text_response = response.text.encode('utf-8').decode('utf-8')

    # 3. Nettoyage markdown
    if text_response.startswith("```json"):
        text_response = text_response[7:].strip()
        if text_response.endswith("```"):
            text_response = text_response[:-3].strip()

    # 4. Parsing JSON
    try:
        json_data = json.loads(text_response)
    except json.JSONDecodeError as e:
        logger.error(f"Erreur d√©codage JSON: {str(e)}")
        raise ValueError(f"R√©ponse non JSON: {text_response[:100]}...")

    # 5. Validation et correction
    if json_data:
        erreurs = validate_json_structure(json_data)
        if erreurs:
            logger.warning(f"JSON invalide, correction en cours")
            json_data = corriger_json(copy.deepcopy(json_data))
            # Sauvegarder le raw
            with open(raw_path, 'w') as f:
                json.dump(json_data_raw, f, indent=2, ensure_ascii=False)

except Exception as e:
    logger.error(f"Erreur: {str(e)}")
    total_errors += 1
```

### 4.2 Probl√®mes identifi√©s

| Probl√®me | Cat√©gorie | Severity | Impact |
|----------|-----------|----------|--------|
| Pas de retry | Robustesse | üî¥ CRITIQUE | Perte d'image sur erreur r√©seau temporaire |
| Pas de timeout | Robustesse | üî¥ CRITIQUE | Gelage du batch |
| raw.json seulement si erreur | Tra√ßabilit√© | üü¢ MOYENNE | Impossible de comparer r√©ponse brute vs corrig√©e |
| Pas de fallback JSON | Robustesse | üü° HAUTE | Si Gemini retourne du texte, image perdue |

### 4.3 Solution propos√©e

**Fonction robuste de validation/correction** :

```python
def valider_et_corriger_json(json_data, img_file, results_dir):
    """
    Valide un JSON et le corrige si n√©cessaire.

    Args:
        json_data: Donn√©es JSON √† valider
        img_file: Nom du fichier image (pour logging)
        results_dir: R√©pertoire pour sauvegarder raw.json

    Returns:
        (json_corrige, √©tait_invalide, erreurs)
    """
    from observations.json_rep.json_sanitizer import validate_json_structure, corriger_json

    erreurs = validate_json_structure(json_data)

    if not erreurs:
        logger.info(f"‚úì JSON valide pour {img_file}")
        return json_data, False, []

    # JSON invalide
    logger.warning(f"‚ö†Ô∏è JSON invalide pour {img_file}. Erreurs: {erreurs}")

    # Toujours sauvegarder le JSON brut
    raw_filename = f"{os.path.splitext(img_file)[0]}_raw.json"
    raw_path = os.path.join(results_dir, raw_filename)
    json_data_raw = copy.deepcopy(json_data)

    with open(raw_path, 'w', encoding='utf-8') as f:
        json.dump(json_data_raw, f, indent=2, ensure_ascii=False)

    logger.info(f"üíæ JSON brut sauvegard√©: {raw_filename}")

    # Corriger le JSON
    json_corrige = corriger_json(json_data_raw)

    # Revalider apr√®s correction
    erreurs_apres = validate_json_structure(json_corrige)

    if erreurs_apres:
        logger.error(f"‚ùå JSON reste invalide apr√®s correction: {erreurs_apres}")
        return None, True, erreurs_apres

    logger.info(f"‚úì JSON corrig√© avec succ√®s pour {img_file}")
    return json_corrige, True, []
```

### 4.4 Priorit√©

**üü° PRIORIT√â HAUTE** - Robustesse du syst√®me

---

## 5. CR√âATION DES ENTR√âES TRANSCRIPTIONOCR

### 5.1 √âtat actuel

**Cr√©ation de TranscriptionOCR** (`pilot/tasks.py:575-597`)

```python
# Cr√©er l'entr√©e TranscriptionOCR
nom_base = _extraire_nom_base_fichier(img_path_relatif)

# Utiliser la fiche import√©e si disponible
if fiche_importee:
    fiche = fiche_importee
else:
    fiche = _trouver_fiche_correspondante(nom_base)

transcription_ocr = TranscriptionOCR.objects.create(
    fiche=fiche,  # ‚ùå PROBL√àME : Peut √™tre None, mais le champ n'est pas nullable !
    chemin_json=json_path_relatif,
    chemin_image=img_path_relatif,
    type_image=type_image,
    modele_ocr=modele_ocr,
    temps_traitement_secondes=duration,
    statut_evaluation='non_evaluee',
)
```

### 5.2 Probl√®mes identifi√©s

#### Probl√®me 1 : Import timezone manquant (CRITIQUE)

**Lignes concern√©es** :
- `pilot/tasks.py:271` (dans `_importer_fiche_depuis_json`)
- `pilot/tasks.py:557` (dans `process_batch_transcription_task`)

```python
# ‚ùå ERREUR : timezone utilis√© mais jamais import√©
date_obs = timezone.make_aware(datetime.datetime(annee, mois, jour, heure, 0))
annee = timezone.now().year
```

**Impact** : **Application crash** avec `NameError: name 'timezone' is not defined`

**Solution** :

```python
# En haut du fichier pilot/tasks.py (apr√®s les autres imports Django)
from django.utils import timezone
```

#### Probl√®me 2 : Champ fiche non nullable (CRITIQUE)

**D√©finition du mod√®le** (`pilot/models.py:26-32`) :

```python
class TranscriptionOCR(models.Model):
    fiche = models.ForeignKey(
        FicheObservation,
        on_delete=models.CASCADE,
        related_name="transcriptions_ocr_pilot",
        verbose_name="Fiche de r√©f√©rence",
        help_text="Fiche d'observation corrig√©e manuellement (v√©rit√© terrain)",
        # ‚ùå MANQUE : null=True, blank=True
    )
```

**Probl√®me** : Le flux demand√© **exclut** l'importation de fiches, donc `fiche` sera toujours `None`.

**Impact** : **Impossible de cr√©er TranscriptionOCR** sans fiche ‚Üí Erreur Django `IntegrityError`

**Solution** :

```python
# Modifier pilot/models.py
fiche = models.ForeignKey(
    FicheObservation,
    on_delete=models.CASCADE,
    related_name="transcriptions_ocr_pilot",
    verbose_name="Fiche de r√©f√©rence",
    help_text="Fiche d'observation corrig√©e manuellement (v√©rit√© terrain)",
    null=True,   # ‚úÖ AJOUTER
    blank=True,  # ‚úÖ AJOUTER
)
```

**Migration n√©cessaire** :

```bash
python manage.py makemigrations pilot
python manage.py migrate
```

### 5.3 Champs remplis dans TranscriptionOCR

**Actuellement** (`pilot/tasks.py:584-592`) :

| Champ | Valeur | Source |
|-------|--------|--------|
| `fiche` | Foreign Key (peut √™tre None) | `fiche_importee` ou `_trouver_fiche_correspondante()` |
| `chemin_json` | Chemin relatif | Calcul√© |
| `chemin_image` | Chemin relatif | Depuis r√©pertoire |
| `type_image` | 'brute' ou 'optimisee' | D√©tect√© depuis chemin |
| `modele_ocr` | Nom du mod√®le | Depuis param√®tre |
| `temps_traitement_secondes` | Float | Chronom√®tre |
| `statut_evaluation` | 'non_evaluee' | D√©faut |
| `date_transcription` | Auto | `auto_now_add=True` |

**Non remplis** (mais pertinents pour √©valuation future) :
- `score_global`, `nombre_champs_corrects`, `nombre_champs_total`
- `nombre_erreurs_*` (tous √† 0)
- `details_comparaison`, `notes_evaluation`

### 5.4 Priorit√©

| Probl√®me | Priorit√© | Effort |
|----------|----------|--------|
| Import timezone manquant | üî¥ CRITIQUE | 1 min |
| Fiche nullable | üî¥ CRITIQUE | 10 min + migration |

---

## 6. PASSAGE DES PARAM√àTRES ENTRE LES VUES

### 6.1 √âtat actuel

**Stockage c√¥t√© client** (`pilot/templates/pilot/selection_repertoire_ocr.html:311-321`)

```javascript
// Stockage dans sessionStorage (navigateur)
const selectedDirs = checked.map(cb => ({
    name: cb.value,
    path: cb.dataset.path
}));

sessionStorage.setItem('selectedDirectories', JSON.stringify(selectedDirs));

window.location = '{% url "pilot:optimisation_ocr_home" %}';
```

**R√©cup√©ration c√¥t√© client** (`pilot/templates/pilot/optimisation_ocr_home.html:132-148`)

```javascript
document.addEventListener('DOMContentLoaded', function() {
    const selectedDirsJSON = sessionStorage.getItem('selectedDirectories');

    if (!selectedDirsJSON) {
        // Erreur : pas de s√©lection
        return;
    }

    const selectedDirs = JSON.parse(selectedDirsJSON);
    // Afficher...
});
```

**Envoi au serveur** (`pilot/templates/pilot/optimisation_ocr_home.html:234-251`)

```javascript
function lancerTranscriptionBatch(directories, modeles, importerEnBase) {
    const formData = new FormData();
    formData.append('directories', JSON.stringify(directories));
    formData.append('modeles_ocr', JSON.stringify(modeles));
    formData.append('importer_en_base', importerEnBase ? 'true' : 'false');

    fetch('{% url "pilot:lancer_transcription_batch" %}', {
        method: 'POST',
        body: formData
    })
}
```

### 6.2 Probl√®mes identifi√©s

| Probl√®me | Severity | Impact |
|----------|----------|--------|
| sessionStorage volatile | üîµ BASSE | Perte si tab ferm√©e, mais POST fonctionne |
| Pas de validation client-side | üîµ BASSE | Donn√©es invalides ‚Üí erreur serveur |
| Perte de contexte en crash | üü¢ MOYENNE | Impossible de savoir ce qui √©tait lanc√© |

### 6.3 Solution propos√©e (optionnelle)

**Ajouter logging avec batch_id** :

```python
def lancer_transcription_batch(request):
    # G√©n√©rer un ID unique pour le batch
    batch_id = f"{request.user.id}_{int(timezone.now().timestamp())}"

    logger.info(
        f"üöÄ [BATCH {batch_id}] Lancement par {request.user.username}: "
        f"{len(directories)} r√©pertoires, {len(modeles_ocr)} mod√®les"
    )

    # Stocker en session
    request.session['pilot_batch_id'] = batch_id

    return JsonResponse({
        'success': True,
        'task_id': task_id,
        'batch_id': batch_id,
    })
```

### 6.4 Priorit√©

**üîµ PRIORIT√â BASSE** - Le syst√®me actuel fonctionne

---

## R√âCAPITULATIF GLOBAL - PRIORIT√âS

### Corrections par ordre de priorit√©

| # | Probl√®me | Fichiers √† modifier | Priorit√© | Effort | Impact |
|---|----------|---------------------|----------|--------|--------|
| 1 | **Import timezone manquant** | `pilot/tasks.py` | üî¥ CRITIQUE | 1 min | √âvite crash application |
| 2 | **Fiche nullable** | `pilot/models.py` | üî¥ CRITIQUE | 10 min + migration | Permet cr√©ation TranscriptionOCR |
| 3 | **D√©tection prompt auto** | `pilot/tasks.py` | üî¥ CRITIQUE | 30 min | Am√©liore qualit√© transcription |
| 4 | **Retry avec backoff** | `pilot/tasks.py` | üî¥ CRITIQUE | 1h | √âvite perte d'images |
| 5 | **Rate limiting** | `pilot/tasks.py` | üî¥ CRITIQUE | 30 min | √âvite ban Google API |
| 6 | **Timeout API** | `pilot/tasks.py` | üü° HAUTE | 30 min | √âvite gelage batch |
| 7 | **Validation JSON robuste** | `pilot/tasks.py` | üü° HAUTE | 1h | Meilleure gestion erreurs |
| 8 | **M√©tadonn√©es JSON** | `pilot/tasks.py` | üü¢ MOYENNE | 30 min | Tra√ßabilit√© |
| 9 | **Optimiser update_state** | `pilot/tasks.py` | üü¢ MOYENNE | 15 min | Performance |
| 10 | **Logging batch** | `pilot/views.py` | üîµ BASSE | 30 min | Debug |

### Quick Wins (priorit√© maximale, effort minimal)

**Total : 2h15 pour les 5 probl√®mes critiques**

1. ‚úÖ **Import timezone** (1 min)
2. ‚úÖ **Fiche nullable** (10 min + migration)
3. ‚úÖ **D√©tection prompt** (30 min)
4. ‚úÖ **Retry backoff** (1h)
5. ‚úÖ **Rate limiting** (30 min)

---

## FICHIERS √Ä MODIFIER - CHECKLIST

### Modifications critiques

- [x] `pilot/tasks.py`
  - [ ] Ajouter `from django.utils import timezone`
  - [ ] Cr√©er `_charger_prompt_selon_type_fiche()`
  - [ ] Cr√©er `retry_with_backoff()`
  - [ ] Cr√©er `apply_rate_limit()`
  - [ ] Modifier boucle r√©pertoires (charger prompt par r√©pertoire)
  - [ ] Ajouter retry √† l'appel API
  - [ ] Ajouter rate limiting
  - [ ] R√©duire fr√©quence update_state

- [x] `pilot/models.py`
  - [ ] Rendre `TranscriptionOCR.fiche` nullable (`null=True, blank=True`)

- [x] `pilot/migrations/`
  - [ ] G√©n√©rer migration pour fiche nullable

### Modifications optionnelles

- [ ] `pilot/tasks.py`
  - [ ] Ajouter m√©tadonn√©es dans JSON
  - [ ] Am√©liorer validation JSON
  - [ ] Ajouter timeout

- [ ] `pilot/views.py`
  - [ ] Ajouter logging avec batch_id

### Exclusions (hors p√©rim√®tre)

- ‚ùå Pas de modification de `_importer_fiche_depuis_json()` (importation en base exclue)
- ‚ùå Pas de modification des mod√®les FicheObservation, Localisation, Nid, etc.

---

## TESTS RECOMMAND√âS

```python
# tests/test_pilot_tasks.py

def test_charger_prompt_ancienne_fiche():
    """Anciennes fiches utilisent le bon prompt"""
    prompt = _charger_prompt_selon_type_fiche("Ancienne_fiche/Sans_traitement")
    assert "VERTICALEMENT" in prompt

def test_charger_prompt_standard():
    """Nouvelles fiches utilisent le prompt standard"""
    prompt = _charger_prompt_selon_type_fiche("Nouvelle_fiche/Traitement_1")
    assert "VERTICALEMENT" not in prompt

def test_retry_backoff_success_first_try():
    """Retry r√©ussit au premier essai"""
    @retry_with_backoff(max_retries=3)
    def func():
        return "success"

    assert func() == "success"

def test_retry_backoff_fails_then_succeeds():
    """Retry r√©ussit apr√®s √©chec"""
    attempts = [0]

    @retry_with_backoff(max_retries=3)
    def func():
        attempts[0] += 1
        if attempts[0] < 2:
            raise Exception("Fail")
        return "success"

    assert func() == "success"
    assert attempts[0] == 2

def test_transcription_ocr_without_fiche():
    """TranscriptionOCR peut √™tre cr√©√© sans fiche"""
    transcription = TranscriptionOCR.objects.create(
        fiche=None,  # Doit fonctionner apr√®s migration
        chemin_json="test.json",
        chemin_image="test.jpg",
        type_image="brute",
        modele_ocr="gemini_2_flash",
        temps_traitement_secondes=2.5,
    )
    assert transcription.pk is not None
```

---

## CONCLUSION

Le flux de transcription pure n√©cessite **5 corrections critiques** pour √™tre op√©rationnel :

1. ‚úÖ **Import timezone** ‚Üí √âvite crash
2. ‚úÖ **Fiche nullable** ‚Üí Permet cr√©ation TranscriptionOCR sans importation
3. ‚úÖ **D√©tection prompt** ‚Üí Am√©liore qualit√© (anciennes fiches)
4. ‚úÖ **Retry API** ‚Üí Robustesse r√©seau
5. ‚úÖ **Rate limiting** ‚Üí √âvite ban Google

**Effort total estim√©** : 2h15

Une fois ces corrections appliqu√©es, le syst√®me sera **robuste et fonctionnel** pour la transcription batch multi-r√©pertoires/multi-mod√®les.

---

**Derni√®re mise √† jour** : 2025-12-20
**Auteur** : Analyse automatis√©e
**Statut** : Pr√™t pour impl√©mentation
