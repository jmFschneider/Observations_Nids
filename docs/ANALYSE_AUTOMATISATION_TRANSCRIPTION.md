# ğŸ“Š Analyse et Proposition d'Automatisation du Pipeline de Transcription

**Date de crÃ©ation** : 25 dÃ©cembre 2025
**Objectif** : Concevoir un processus automatisÃ© pour traiter plusieurs dizaines de milliers de fiches d'observation sans intervention humaine

---

## ğŸ“‹ Table des matiÃ¨res

1. [Contexte et Objectifs](#1-contexte-et-objectifs)
2. [Analyse du Processus Actuel](#2-analyse-du-processus-actuel)
3. [Points de Blocage pour le Passage Ã  l'Ã‰chelle](#3-points-de-blocage-pour-le-passage-Ã -lÃ©chelle)
4. [Architecture ProposÃ©e pour l'Automatisation](#4-architecture-proposÃ©e-pour-lautomatisation)
5. [StratÃ©gie de Gestion des Erreurs](#5-stratÃ©gie-de-gestion-des-erreurs)
6. [Feuille de Route d'ImplÃ©mentation](#6-feuille-de-route-dimplÃ©mentation)

---

## 1. Contexte et Objectifs

### 1.1 Reformulation de la Demande

#### Situation Actuelle
Nous disposons d'un **processus de transcription segmentÃ© en plusieurs Ã©tapes manuelles** :
1. Images de fiches â†’ Transcription OCR (Gemini) â†’ Fichiers JSON
2. Import JSON â†’ Extraction candidats â†’ Validation espÃ¨ces â†’ PrÃ©paration importations â†’ Finalisation
3. Chaque Ã©tape nÃ©cessite une **intervention humaine** pour passer Ã  la suivante

#### Contrainte d'Ã‰chelle
- âœ… **Fonctionne bien** : quelques dizaines ou centaines de fiches
- âŒ **Ne passe pas Ã  l'Ã©chelle** : plusieurs dizaines de milliers de fiches

#### Objectif RecherchÃ©
Concevoir un **processus automatisÃ© de bout en bout** qui :

1. **Minimise les erreurs** au maximum
2. **Fonctionne sans intervention humaine** de l'image jusqu'Ã  la base de donnÃ©es
3. L'humain n'intervient **qu'APRÃˆS** : pour la relecture/validation des fiches dÃ©jÃ  en base

### 1.2 PÃ©rimÃ¨tre

**En entrÃ©e** : Plusieurs dizaines de milliers d'images de fiches d'observation
**En sortie** : Fiches complÃ¨tes en base de donnÃ©es, prÃªtes pour relecture humaine
**Contrainte forte** : Aucune intervention humaine pendant le processus

---

## 2. Analyse du Processus Actuel

### 2.1 Vue d'Ensemble du Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PILOT APP - OCR/TRANSCRIPTION                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    Images (media/) â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  1. SÃ©lection des rÃ©pertoires d'images       â”‚ â† MANUEL
        â”‚     (selection_repertoire_ocr)               â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  2. Lancement de la transcription batch      â”‚ â† MANUEL
        â”‚     (lancer_transcription_batch)             â”‚
        â”‚     - SÃ©lection des modÃ¨les Gemini           â”‚
        â”‚     - Configuration du batch                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  3. Traitement OCR asynchrone (Celery)       â”‚ â† AUTOMATIQUE
        â”‚     process_batch_transcription_task         â”‚
        â”‚     - DÃ©tection auto du type de fiche        â”‚
        â”‚     - Appel Gemini API (timeout + retry)     â”‚
        â”‚     - Validation JSON                         â”‚
        â”‚     - Correction automatique                  â”‚
        â”‚     - Sauvegarde JSON + TranscriptionOCR      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    JSON Files crÃ©Ã©s â”‚
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        INGEST APP - IMPORT EN BASE                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  4. Import des fichiers JSON                 â”‚ â† MANUEL
        â”‚     (importer_json)                          â”‚
        â”‚     - SÃ©lection du rÃ©pertoire                â”‚
        â”‚     - CrÃ©ation TranscriptionBrute            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  5. Extraction des candidats                 â”‚ â† MANUEL
        â”‚     (extraire_candidats)                     â”‚
        â”‚     - Extraction espÃ¨ces (auto-match 0.8)    â”‚
        â”‚     - CrÃ©ation utilisateurs auto             â”‚
        â”‚     - GÃ©ocodage communes                      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  6. Validation des espÃ¨ces                   â”‚ â† MANUEL âš ï¸
        â”‚     (liste_especes_candidates)               â”‚
        â”‚     - Revue des correspondances auto         â”‚
        â”‚     - Validation manuelle                     â”‚
        â”‚     - Lien vers Espece validÃ©e                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  7. PrÃ©paration des importations             â”‚ â† MANUEL
        â”‚     (preparer_importations)                  â”‚
        â”‚     - CrÃ©ation ImportationEnCours            â”‚
        â”‚     - Statut: en_attente                      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  8. Revue optionnelle                        â”‚ â† MANUEL (optionnel)
        â”‚     (liste_importations)                     â”‚
        â”‚     - Visualisation JSON                      â”‚
        â”‚     - ContrÃ´le qualitÃ© prÃ©-finalisation       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  9. Finalisation                             â”‚ â† MANUEL âš ï¸
        â”‚     (finaliser_importation)                  â”‚
        â”‚     - CrÃ©ation FicheObservation              â”‚
        â”‚     - CrÃ©ation objets liÃ©s                    â”‚
        â”‚     - Transaction atomique                    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                Fiches en base de donnÃ©es â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  10. Relecture et correction                 â”‚ â† POST-IMPORT
        â”‚      (view_transcription)                    â”‚
        â”‚      - Correction manuelle si nÃ©cessaire      â”‚
        â”‚      - Validation finale                      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 DÃ©tail des Ã‰tapes Automatiques

#### Ã‰tape 3 : Traitement OCR (process_batch_transcription_task)

**Fichier** : `pilot/tasks.py`

**Processus** :
```python
For each OCR model (gemini_3_flash, gemini_3_pro, etc.):
    For each directory:
        For each image:
            1. DÃ©tection automatique du type de fiche
               - Recherche "ancien"/"Ancien" dans le chemin
               - Charge prompt_gemini_transcription.txt (moderne)
               - OU prompt_gemini_transcription_Ancienne_Fiche.txt (annÃ©es 70-80)

            2. Appel API Gemini
               - Timeout: 120 secondes
               - Retry: 3 tentatives avec backoff exponentiel (2s â†’ 4s â†’ 8s â†’ 16s)
               - Rate limiting: 60 req/min

            3. Validation JSON
               - validate_json_structure() retourne liste d'erreurs
               - VÃ©rifie structure attendue (informations_generales, nid, etc.)

            4. Correction automatique
               - corriger_json() corrige noms de champs courants
               - Sauvegarde _raw.json si corrections appliquÃ©es

            5. Sauvegarde
               - {image_name}_result.json (JSON corrigÃ©)
               - CrÃ©ation TranscriptionOCR (mÃ©tadonnÃ©es d'Ã©valuation)
               - Suivi progression dans session + Redis
```

**Structure JSON Attendue** :
```json
{
  "informations_generales": {
    "n_fiche": "...",
    "observateur": "...",
    "n_espece": "...",
    "espece": "...",
    "annee": "..."
  },
  "nid": {
    "nid_prec_t_meme_c_ple": true/false,
    "haut_nid": "...",
    "h_c_vert": "...",
    "nid": "description..."
  },
  "localisation": {
    "IGN_50000": "...",
    "commune": "...",
    "dep_t": "...",
    "coordonnees_et_ou_lieu_dit": "...",
    "altitude": "...",
    "paysage": "...",
    "alentours": "..."
  },
  "tableau_donnees": [
    {
      "Jour": 17,
      "Mois": 7,
      "Heure": 12,
      "Nombre_oeuf": 0,
      "Nombre_pou": 3,
      "age": null,
      "observations": "..."
    }
  ],
  "tableau_donnees_2": {
    "1er_o_pondu": {"jour": null, "Mois": null, "Precision": null},
    "1er_p_eclos": {"jour": null, "Mois": null, "Precision": null},
    "1er_p_volant": {"jour": null, "Mois": null, "Precision": null},
    "nombre_oeufs": {"pondus": null, "eclos": null, "n_ecl": null},
    "nombre_poussins": {"1/2": null, "3/4": "3", "vol_t": "3"}
  },
  "causes_echec": {
    "causes_d_echec": "..."
  },
  "remarque": "..." (optionnel)
}
```

**Gestion des Erreurs** :
| Erreur | Action | Impact |
|--------|--------|--------|
| Timeout API | Retry 3x avec backoff | Image sautÃ©e si Ã©chec total |
| JSON Parse Error | Log + continue | Sauvegarde rÃ©ponse brute |
| JSON invalide | Auto-correction | Sauvegarde raw + corrigÃ© |
| Rate limit | Attente 1s entre requÃªtes | PrÃ©vention ban API |
| Fichier introuvable | Log + continue | Image ignorÃ©e |

#### Ã‰tape 5 : Extraction des Candidats (extraire_donnees_candidats)

**Fichier** : `ingest/importation_service.py`

**Processus** :
```python
For each TranscriptionBrute (traite=False):
    1. Extraction EspÃ¨ce
       - nom_espece = json['informations_generales']['espece']
       - CrÃ©ation/rÃ©cupÃ©ration EspeceCandidate
       - Auto-matching avec SequenceMatcher (threshold: 0.8)
       - Recherche dans toutes les Espece de la base
       - Score de similaritÃ© stockÃ©
       - Si score â‰¥ 0.8 â†’ espece_validee auto-remplie
       - Si score < 0.8 â†’ espece_validee = None (validation manuelle requise)

    2. Extraction Observateur
       - nom_observateur = json['informations_generales']['observateur']
       - Appel creer_ou_recuperer_utilisateur(nom_observateur)
       - Parsing intelligent :
         * "PrÃ©nom Nom" â†’ first_name="PrÃ©nom", last_name="Nom"
         * "NOM" â†’ first_name="NOM", last_name="NOM"
       - Recherche utilisateur existant (first_name + last_name, case-insensitive)
       - Si trouvÃ© â†’ mise Ã  jour est_transcription=True
       - Si pas trouvÃ© â†’ crÃ©ation automatique :
         * username: prenom.nom (unique avec compteur si collision)
         * email: prenom.nom@transcription.trans (avec fallback si collision)
         * est_transcription=True, est_valide=True
         * role='observateur'

    3. GÃ©ocodage Commune
       - commune = json['localisation']['commune'] ou json['localisation']['IGN_50000']
       - departement = json['localisation']['dep_t']
       - Appel geocodeur.geocoder_commune(commune, departement)
       - Recherche via API Google Maps ou IGN
       - RÃ©cupÃ©ration : lat, lon, altitude, adresse complÃ¨te
       - Si Ã©chec â†’ utilise nom brut, log warning
       - CrÃ©ation/mise Ã  jour CommuneFrance si succÃ¨s
```

**Auto-Matching d'EspÃ¨ces** :
```python
def _trouver_correspondance_espece(self, espece_candidate):
    """
    Auto-match avec SequenceMatcher (difflib)
    Threshold: 0.8 (80% de similaritÃ©)
    """
    nom_transcrit = espece_candidate.nom_transcrit.lower()
    meilleure_correspondance = None
    meilleur_score = 0

    for espece in Espece.objects.all():
        # Compare avec nom_commun et nom_scientifique
        score_commun = SequenceMatcher(None, nom_transcrit, espece.nom_commun.lower()).ratio()
        score_sci = SequenceMatcher(None, nom_transcrit, espece.nom_scientifique.lower()).ratio()
        score = max(score_commun, score_sci)

        if score > meilleur_score:
            meilleur_score = score
            meilleure_correspondance = espece

    if meilleur_score >= 0.8:
        espece_candidate.espece_validee = meilleure_correspondance
        espece_candidate.score_similarite = round(meilleur_score * 100, 1)
        espece_candidate.save()
```

**Statistiques RetournÃ©es** :
- `especes_ajoutees` : Nombre de nouveaux EspeceCandidate crÃ©Ã©s
- `utilisateurs_crees` : Nombre de nouveaux Utilisateur crÃ©Ã©s
- `communes_geocodees` : Nombre de communes gÃ©ocodÃ©es avec succÃ¨s

#### Ã‰tape 9 : Finalisation (finaliser_importation)

**Fichier** : `ingest/importation_service.py`

**Transaction Atomique** (tout ou rien) :
```python
@transaction.atomic
def finaliser_importation(self, importation_id):
    importation = ImportationEnCours.objects.select_for_update().get(id=importation_id)

    # 1. VALIDATIONS BLOQUANTES
    if not importation.espece_candidate or not importation.espece_candidate.espece_validee:
        â†’ importation.statut = 'erreur'
        â†’ return False, "EspÃ¨ce non validÃ©e"

    if not importation.observateur:
        â†’ importation.statut = 'erreur'
        â†’ return False, "Observateur non trouvÃ©"

    # 2. EXTRACTION DONNÃ‰ES
    donnees = importation.transcription.json_brut
    annee = donnees['informations_generales'].get('annee') or timezone.now().year

    # 3. CRÃ‰ATION FICHE OBSERVATION
    fiche = FicheObservation.objects.create(
        observateur=importation.observateur,
        espece=importation.espece_candidate.espece_validee,
        annee=annee,
        chemin_image=...,  # Extrait du nom de fichier
        chemin_json=...,   # Extrait du nom de fichier
        transcription=True  # Marque comme issu d'OCR
    )

    # 4. CRÃ‰ATION OBJETS LIÃ‰S (auto-crÃ©Ã©s)

    # 4.1 Localisation
    localisation = Localisation.objects.create(
        fiche=fiche,
        commune=donnees['localisation'].get('commune'),
        code_insee=...,  # RÃ©cupÃ©rÃ© via gÃ©ocodage
        departement=donnees['localisation'].get('dep_t'),
        lieu_dit=donnees['localisation'].get('coordonnees_et_ou_lieu_dit'),
        altitude=donnees['localisation'].get('altitude'),
        latitude=...,    # RÃ©cupÃ©rÃ© via gÃ©ocodage
        longitude=...,   # RÃ©cupÃ©rÃ© via gÃ©ocodage
        source_coordonnees='geocodage_auto',
        precision_gps='commune'
    )

    # 4.2 Nid
    nid = Nid.objects.create(
        fiche=fiche,
        hauteur_nid=donnees['nid'].get('haut_nid'),
        hauteur_sol_vegetation=donnees['nid'].get('h_c_vert'),
        nid_precedent_meme_couple=donnees['nid'].get('nid_prec_t_meme_c_ple'),
        description=donnees['nid'].get('nid')
    )

    # 4.3 Observations (multiple)
    for obs_data in donnees['tableau_donnees']:
        try:
            Observation.objects.create(
                fiche=fiche,
                date=construct_date(obs_data['Jour'], obs_data['Mois'], annee),
                heure=obs_data.get('Heure'),
                nombre_oeufs=obs_data.get('Nombre_oeuf'),
                nombre_poussins=obs_data.get('Nombre_pou'),
                observations=obs_data.get('observations')
            )
        except (ValueError, KeyError) as e:
            # EntrÃ©e invalide â†’ skip, log warning
            logger.warning(f"Observation invalide ignorÃ©e: {e}")
            continue

    # 4.4 ResumeObservation (avec auto-correction contraintes)
    resume_data = donnees['tableau_donnees_2']
    nombre_oeufs = resume_data['nombre_oeufs']
    nombre_poussins = resume_data['nombre_poussins']

    # Auto-correction logique
    pondus = nombre_oeufs.get('pondus') or 0
    eclos = nombre_oeufs.get('eclos') or 0
    volants = int(nombre_poussins.get('vol_t') or 0)

    # Contrainte: volants <= eclos <= pondus
    if volants > eclos:
        logger.warning(f"Correction: {volants} volants > {eclos} Ã©clos â†’ ajustement")
        eclos = volants
    if eclos > pondus:
        logger.warning(f"Correction: {eclos} Ã©clos > {pondus} pondus â†’ ajustement")
        pondus = eclos

    ResumeObservation.objects.create(
        fiche=fiche,
        oeufs_pondus=pondus,
        oeufs_eclos=eclos,
        poussins_volants=volants,
        # ... autres champs
    )

    # 4.5 CausesEchec
    if donnees['causes_echec'].get('causes_d_echec'):
        CausesEchec.objects.create(
            fiche=fiche,
            cause=donnees['causes_echec']['causes_d_echec']
        )

    # 4.6 Remarque (optionnel)
    if donnees.get('remarque'):
        Remarque.objects.create(
            fiche=fiche,
            texte=donnees['remarque']
        )

    # 4.7 EtatCorrection (pour workflow de correction)
    EtatCorrection.objects.create(
        fiche=fiche,
        statut='en_cours'  # PrÃªt pour relecture manuelle
    )

    # 5. MISE Ã€ JOUR IMPORTATION
    importation.fiche_observation = fiche
    importation.statut = 'complete'
    importation.save()

    return True, f"Fiche {fiche.id} crÃ©Ã©e avec succÃ¨s"
```

**Gestion des Erreurs en Finalisation** :
| Erreur | Action | Statut | Rollback |
|--------|--------|--------|----------|
| EspÃ¨ce non validÃ©e | Bloque | erreur | N/A (pas crÃ©Ã©) |
| Observateur manquant | Bloque | erreur | N/A (pas crÃ©Ã©) |
| Contrainte BD violÃ©e | Auto-correction si possible | Logs | Continue |
| Exception transaction | Annule tout | erreur | OUI (atomique) |
| GÃ©ocodage Ã©chouÃ© | Utilise nom brut | Warning | Continue |

### 2.3 DÃ©tail des Ã‰tapes Manuelles

#### ğŸš« Ã‰tape 6 : Validation des EspÃ¨ces (BLOQUANTE)

**Fichier** : `ingest/views/especes.py`

**Pourquoi c'est manuel** :
- Auto-matching peut Ã©chouer (score < 0.8)
- Variantes orthographiques : "Gravelot Ã  collier" vs "Gravelot Ã  collï¿½er" (OCR)
- Noms vernaculaires multiples : "MÃ©sange charbonniÃ¨re" = "Parus major"
- Nouvelles espÃ¨ces non en base

**Interface** :
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EspÃ¨ces Candidates                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Nom Transcrit          | Score | EspÃ¨ce ValidÃ©e | Action    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Gobemouche gris        | 100%  | Gobemouche gris | âœ“ ValidÃ© â”‚
â”‚ Gravelot Ã  collï¿½er     | 75%   | [Ã€ valider]     | [SELECT] â”‚
â”‚ LINOTTE                | 68%   | [Ã€ valider]     | [SELECT] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Actions disponibles** :
- Lier Ã  une espÃ¨ce existante (dropdown avec recherche)
- CrÃ©er nouvelle espÃ¨ce si inexistante
- Validation en masse (si score â‰¥ seuil)

**Impact si non validÃ©** :
â†’ Impossible de finaliser l'importation (erreur bloquante)

#### ğŸš« Ã‰tape 9 : Finalisation (ACTION MANUELLE)

**Pourquoi c'est manuel** :
- Bouton "Finaliser" Ã  cliquer pour chaque ImportationEnCours
- Ou sÃ©lection multiple + "Finaliser les importations sÃ©lectionnÃ©es"

**Interface** :
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Importations En Attente                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [âœ“] ID 123 | Gobemouche gris | Alexandre Delasalle | âœ“     â”‚
â”‚ [âœ“] ID 124 | Accenteur mouchet | ALE | âœ“                   â”‚
â”‚ [ ] ID 125 | Moineau domestique | C. JACOB | âœ— (erreur)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [Finaliser les sÃ©lectionnÃ©es]                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pourquoi ce n'est pas automatique** :
- Permet revue optionnelle avant crÃ©ation en base
- ContrÃ´le qualitÃ© prÃ©-finalisation
- Historiquement conÃ§u pour validation humaine

---

## 3. Points de Blocage pour le Passage Ã  l'Ã‰chelle

### 3.1 Interventions Manuelles Obligatoires

| Ã‰tape | Type | FrÃ©quence | Impact sur ScalabilitÃ© |
|-------|------|-----------|------------------------|
| **1. SÃ©lection rÃ©pertoires OCR** | Navigation UI | Par batch | âš ï¸ Moyen - automatisable |
| **2. Lancement transcription** | Clic bouton | Par batch | âš ï¸ Moyen - automatisable |
| **4. Import JSON** | SÃ©lection rÃ©pertoire | Par batch | âš ï¸ Moyen - automatisable |
| **5. Extraction candidats** | Clic bouton | Par batch | âš ï¸ Moyen - automatisable |
| **6. Validation espÃ¨ces** | Revue manuelle | **Par espÃ¨ce unique** | ğŸ”´ **CRITIQUE** - bloquant |
| **7. PrÃ©paration importations** | Clic bouton | Par batch | âš ï¸ Moyen - automatisable |
| **9. Finalisation** | Clic bouton | **Par fiche** | ğŸ”´ **CRITIQUE** - bloquant |

### 3.2 Analyse de l'Impact

#### ğŸ”´ Validation des EspÃ¨ces (Ã‰tape 6)

**Volume estimÃ©** :
- 50 000 fiches Ã— ~150 espÃ¨ces diffÃ©rentes = ~150 espÃ¨ces candidates uniques
- Auto-match Ã  80% = ~30 espÃ¨ces Ã  valider manuellement
- Temps : ~2 min/espÃ¨ce = **~1 heure de travail manuel**

**Impact** : âœ… **GÃ©rable** avec l'automatisation actuelle

**Mais** : Bloque le processus â†’ nÃ©cessite intervention avant finalisation

#### ğŸ”´ Finalisation des Importations (Ã‰tape 9)

**Volume estimÃ©** :
- 50 000 fiches Ã— 1 clic = **50 000 clics** (ou sÃ©lection en masse)
- Temps : ~2 sec/fiche en masse = **~28 heures de clics**

**Impact** : ğŸ”´ **INACCEPTABLE** pour passage Ã  l'Ã©chelle

**Solution requise** : Finalisation automatique en masse

### 3.3 Goulots d'Ã‰tranglement Techniques

#### 3.3.1 Performance OCR (Gemini API)

**Limites actuelles** :
- Rate limit : 60 requÃªtes/minute
- Timeout : 120 secondes/image
- Retry : 3 tentatives max

**Calcul pour 50 000 images** :
```
Temps thÃ©orique minimum (60 req/min) :
50 000 images Ã· 60 images/min = 833 minutes = ~14 heures

Temps rÃ©el avec retries et erreurs (~10% Ã©chec) :
14 heures Ã— 1.3 (overhead) = ~18 heures
```

**Conclusion** : âœ… Acceptable (peut tourner en arriÃ¨re-plan sur 24-48h)

#### 3.3.2 Performance Base de DonnÃ©es (Finalisation)

**Volume par fiche finalisÃ©e** :
- 1 FicheObservation
- 1 Localisation (avec gÃ©ocodage)
- 1 Nid
- ~5-10 Observation (moyenne)
- 1 ResumeObservation
- ~0.5 CausesEchec (si applicable)
- ~0.3 Remarque (si applicable)
- 1 EtatCorrection

**Total** : ~10-15 INSERT par fiche

**Calcul pour 50 000 fiches** :
```
50 000 fiches Ã— 12 INSERT/fiche = 600 000 INSERT

Avec PostgreSQL optimisÃ© :
- Bulk insert : ~5000 INSERT/sec
- Transaction par fiche : ~100 fiches/sec

Temps estimÃ© :
- Bulk : 600 000 Ã· 5000 = 120 secondes = 2 minutes
- SÃ©quentiel : 50 000 Ã· 100 = 500 secondes = 8 minutes
```

**Conclusion** : âœ… Performance BD non limitante

#### 3.3.3 GÃ©ocodage API (Google Maps / IGN)

**Limites** :
- Google Maps : ~50 requÃªtes/sec (avec clÃ© API payante)
- IGN : ~10 requÃªtes/sec (gratuit)

**Volume** :
- 50 000 fiches Ã— 1 gÃ©ocodage/fiche = 50 000 requÃªtes
- Beaucoup de communes en double â†’ cache efficace

**Optimisation avec cache** :
```
Communes uniques en France : ~35 000
Communes dans fiches : ~500 (estimation)
Cache hit rate : ~99% aprÃ¨s 500 premiÃ¨res

Temps :
- 500 nouvelles communes Ã· 10 req/sec = 50 secondes
- Cache pour le reste = instantanÃ©
```

**Conclusion** : âœ… GÃ©ocodage non limitant avec cache

---

## 4. Architecture ProposÃ©e pour l'Automatisation

### 4.1 Principe Directeur

**Pipeline EntiÃ¨rement AutomatisÃ©** :
```
Images â†’ OCR â†’ JSON â†’ Import â†’ Extraction â†’ Validation Auto â†’ Finalisation Auto â†’ Base de DonnÃ©es
         â†“                                           â†“                    â†“
     Celery Task                              Auto-Matching         Bulk Processing
                                              (threshold 0.7)      (transaction/batch)
```

**Intervention humaine** : Uniquement APRÃˆS finalisation, pour relecture des fiches en base

### 4.2 Architecture DÃ©taillÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PHASE 1 : PRÃ‰PARATION DES IMAGES                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  1.1 Scan automatique du rÃ©pertoire media/           â”‚
        â”‚      - DÃ©tection rÃ©cursive de toutes les images      â”‚
        â”‚      - Filtrage par extension (.jpg, .png)           â”‚
        â”‚      - Groupement par rÃ©pertoire                      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  1.2 DÃ©tection du type de fiche                      â”‚
        â”‚      - Analyse du chemin (regex: ancien/Ancien)      â”‚
        â”‚      - Attribution du prompt appropriÃ©                â”‚
        â”‚      - Tag metadata dans PreparationImage            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PHASE 2 : TRANSCRIPTION OCR BATCH                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  2.1 Lancement automatique Celery                    â”‚
        â”‚      - Queue : high_priority (OCR)                   â”‚
        â”‚      - Concurrency : 10 workers parallÃ¨les           â”‚
        â”‚      - ModÃ¨le : gemini-2.5-flash-lite (rapide)       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  2.2 Traitement parallÃ¨le avec gestion d'erreurs     â”‚
        â”‚      - Timeout : 120s avec retry exponentiel         â”‚
        â”‚      - Rate limiting : 60 req/min auto-throttle      â”‚
        â”‚      - Validation JSON + auto-correction             â”‚
        â”‚      - Sauvegarde _result.json + _raw.json           â”‚
        â”‚      - CrÃ©ation TranscriptionOCR (mÃ©tadonnÃ©es)       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  2.3 Monitoring et alertes                           â”‚
        â”‚      - Dashboard temps rÃ©el (Celery Flower)          â”‚
        â”‚      - Alertes si taux d'Ã©chec > 5%                  â”‚
        â”‚      - Logs dÃ©taillÃ©s des erreurs                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    JSON Files prÃªts â”‚
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PHASE 3 : IMPORT AUTOMATIQUE                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  3.1 DÃ©tection automatique nouveaux JSON             â”‚
        â”‚      - Watcher filesystem (watchdog library)         â”‚
        â”‚      - OU Cron job toutes les 5 minutes              â”‚
        â”‚      - Filtre : *_result.json non importÃ©s           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  3.2 Import batch TranscriptionBrute                 â”‚
        â”‚      - Bulk create (500 fiches/batch)                â”‚
        â”‚      - Skip duplicates (check fichier_source)        â”‚
        â”‚      - Transaction par batch                          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  3.3 Extraction automatique candidats                â”‚
        â”‚      - Trigger automatique aprÃ¨s import              â”‚
        â”‚      - Extraction espÃ¨ces + auto-matching            â”‚
        â”‚      - CrÃ©ation utilisateurs automatique              â”‚
        â”‚      - GÃ©ocodage avec cache (Redis)                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 4 : VALIDATION INTELLIGENTE                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  4.1 Auto-validation des espÃ¨ces                     â”‚
        â”‚      - Seuil abaissÃ© : 0.7 (au lieu de 0.8)          â”‚
        â”‚      - Validation automatique si score â‰¥ 0.7         â”‚
        â”‚      - Flag pour revue manuelle si score < 0.7       â”‚
        â”‚      - Machine learning : amÃ©lioration du matching   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  4.2 Dictionnaire d'Ã©quivalences                     â”‚
        â”‚      - Table : EspeceEquivalence                     â”‚
        â”‚      - Mapping : "LINOTTE" â†’ "Linotte mÃ©lodieuse"    â”‚
        â”‚      - Apprentissage : sauvegarde validations manu.  â”‚
        â”‚      - Auto-application des Ã©quivalences connues     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  4.3 File d'attente de validation manuelle           â”‚
        â”‚      - Queue : species_to_validate                   â”‚
        â”‚      - Filtrage : score < 0.7                        â”‚
        â”‚      - Priorisation : espÃ¨ces frÃ©quentes en premier  â”‚
        â”‚      - Interface dÃ©diÃ©e pour validation rapide       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 5 : FINALISATION AUTOMATIQUE                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  5.1 Trigger automatique de finalisation             â”‚
        â”‚      - Condition : espece_validee IS NOT NULL        â”‚
        â”‚      - Celery task : auto_finalize_importations      â”‚
        â”‚      - FrÃ©quence : toutes les 10 minutes             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  5.2 Finalisation en batch                           â”‚
        â”‚      - SÃ©lection : ImportationEnCours (en_attente)   â”‚
        â”‚      - Batch size : 100 fiches/transaction           â”‚
        â”‚      - Transaction atomique par batch                 â”‚
        â”‚      - Rollback si erreur dans le batch              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  5.3 Gestion des erreurs de finalisation             â”‚
        â”‚      - Retry 3x avec backoff si erreur technique     â”‚
        â”‚      - Marquage 'erreur' si Ã©chec dÃ©finitif          â”‚
        â”‚      - Alerte email/Slack pour erreurs persistantes  â”‚
        â”‚      - Dead letter queue pour analyse manuelle       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 6 : CONTRÃ”LE QUALITÃ‰ POST-IMPORT               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  6.1 Marquage EtatCorrection                         â”‚
        â”‚      - Toutes fiches : statut='en_cours'             â”‚
        â”‚      - PrÃªtes pour relecture humaine                  â”‚
        â”‚      - Interface de correction existante (no change) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  6.2 Scoring automatique de confiance                â”‚
        â”‚      - Score OCR : qualitÃ© JSON (0-100)              â”‚
        â”‚      - Score espÃ¨ce : similaritÃ© auto-match          â”‚
        â”‚      - Score global : moyenne pondÃ©rÃ©e               â”‚
        â”‚      - Priorisation relecture : score faible d'abord â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  6.3 Dashboard de monitoring                          â”‚
        â”‚      - Taux de rÃ©ussite par Ã©tape                    â”‚
        â”‚      - Distribution des scores de confiance          â”‚
        â”‚      - EspÃ¨ces problÃ©matiques rÃ©currentes            â”‚
        â”‚      - Temps de traitement moyen                      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                Fiches en base, prÃªtes pour relecture â”‚
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  INTERVENTION HUMAINE : Relecture et validation      â”‚
        â”‚  - Interface : view_transcription (existante)        â”‚
        â”‚  - Priorisation : fiches score < 80                  â”‚
        â”‚  - Correction manuelle si nÃ©cessaire                  â”‚
        â”‚  - Validation finale : statut='valide'               â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.3 Composants Ã  DÃ©velopper

#### 4.3.1 Watcher Filesystem (Nouveau)

**Fichier** : `pilot/watcher.py`

```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
import time

class JSONWatcher(FileSystemEventHandler):
    """
    Surveille media/transcription_results/ pour nouveaux JSON
    DÃ©clenche import automatique
    """

    def on_created(self, event):
        if event.src_path.endswith('_result.json'):
            # DÃ©clenche import_json_auto.delay(event.src_path)
            pass

def start_watcher():
    observer = Observer()
    observer.schedule(JSONWatcher(), path="media/transcription_results", recursive=True)
    observer.start()

    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        observer.stop()
    observer.join()
```

**Alternative** : Cron job Django (`django-cron` ou Celery Beat)

```python
# ingest/tasks.py
from celery import shared_task

@shared_task
def auto_import_new_json():
    """
    Cron : toutes les 5 minutes
    Scanne transcription_results/ pour nouveaux JSON
    """
    base_dir = settings.MEDIA_ROOT / 'transcription_results'

    for json_file in base_dir.rglob('*_result.json'):
        if not TranscriptionBrute.objects.filter(fichier_source=json_file.name).exists():
            # Import automatique
            ImportationService().importer_fichier_json(json_file)
```

#### 4.3.2 Auto-Finalisation Celery (Nouveau)

**Fichier** : `ingest/tasks.py`

```python
@shared_task
def auto_finalize_pending_importations():
    """
    Cron : toutes les 10 minutes
    Finalise toutes ImportationEnCours (en_attente) avec espÃ¨ce validÃ©e
    """
    service = ImportationService()

    # SÃ©lection des importations prÃªtes
    pending = ImportationEnCours.objects.filter(
        statut='en_attente',
        espece_candidate__espece_validee__isnull=False,
        observateur__isnull=False
    )

    results = {
        'success': 0,
        'errors': 0,
        'error_details': []
    }

    # Finalisation en batch de 100
    for batch in chunked(pending, 100):
        for importation in batch:
            try:
                success, message = service.finaliser_importation(importation.id)
                if success:
                    results['success'] += 1
                else:
                    results['errors'] += 1
                    results['error_details'].append({
                        'id': importation.id,
                        'error': message
                    })
            except Exception as e:
                results['errors'] += 1
                results['error_details'].append({
                    'id': importation.id,
                    'error': str(e)
                })
                logger.error(f"Auto-finalization error for {importation.id}: {e}")

    # Alerte si taux d'erreur > 10%
    if results['errors'] / (results['success'] + results['errors']) > 0.1:
        send_alert_email(
            subject="Taux d'erreur Ã©levÃ© dans auto-finalisation",
            body=f"Erreurs : {results['errors']}, SuccÃ¨s : {results['success']}\n"
                 f"DÃ©tails : {results['error_details']}"
        )

    return results
```

#### 4.3.3 Table EspeceEquivalence (Nouveau modÃ¨le)

**Fichier** : `ingest/models.py`

```python
class EspeceEquivalence(models.Model):
    """
    Dictionnaire d'apprentissage pour matching espÃ¨ces
    Sauvegarde les validations manuelles pour rÃ©utilisation
    """
    nom_transcrit = models.CharField(max_length=200, unique=True, db_index=True)
    espece_validee = models.ForeignKey('taxonomy.Espece', on_delete=models.CASCADE)
    score_confiance = models.FloatField(default=100.0)  # 100 = validation manuelle
    nombre_utilisations = models.IntegerField(default=0)
    date_creation = models.DateTimeField(auto_now_add=True)
    date_derniere_utilisation = models.DateTimeField(auto_now=True)

    class Meta:
        db_table = 'ingest_espece_equivalence'
        verbose_name = "Ã‰quivalence d'espÃ¨ce"
        indexes = [
            models.Index(fields=['nom_transcrit']),
        ]

    def __str__(self):
        return f"{self.nom_transcrit} â†’ {self.espece_validee.nom_commun}"
```

**Utilisation dans auto-matching** :

```python
def _trouver_correspondance_espece_amelioree(self, espece_candidate):
    """
    Auto-matching amÃ©liorÃ© avec apprentissage
    1. Cherche dans EspeceEquivalence (exact match)
    2. SequenceMatcher avec threshold 0.7 (au lieu de 0.8)
    3. Machine learning (optionnel, phase 2)
    """
    nom_transcrit = espece_candidate.nom_transcrit

    # 1. Exact match dans dictionnaire
    equivalence = EspeceEquivalence.objects.filter(nom_transcrit__iexact=nom_transcrit).first()
    if equivalence:
        espece_candidate.espece_validee = equivalence.espece_validee
        espece_candidate.score_similarite = equivalence.score_confiance
        espece_candidate.save()

        # IncrÃ©menter compteur d'utilisation
        equivalence.nombre_utilisations += 1
        equivalence.save()
        return True

    # 2. SequenceMatcher avec threshold abaissÃ©
    meilleure_correspondance = None
    meilleur_score = 0

    for espece in Espece.objects.all():
        score_commun = SequenceMatcher(None, nom_transcrit.lower(), espece.nom_commun.lower()).ratio()
        score_sci = SequenceMatcher(None, nom_transcrit.lower(), espece.nom_scientifique.lower()).ratio()
        score = max(score_commun, score_sci)

        if score > meilleur_score:
            meilleur_score = score
            meilleure_correspondance = espece

    # Threshold abaissÃ© Ã  0.7 pour automatisation
    if meilleur_score >= 0.7:
        espece_candidate.espece_validee = meilleure_correspondance
        espece_candidate.score_similarite = round(meilleur_score * 100, 1)
        espece_candidate.save()

        # CrÃ©er Ã©quivalence pour apprentissage
        EspeceEquivalence.objects.get_or_create(
            nom_transcrit=nom_transcrit,
            defaults={
                'espece_validee': meilleure_correspondance,
                'score_confiance': espece_candidate.score_similarite
            }
        )
        return True

    # Score < 0.7 â†’ validation manuelle requise
    return False
```

#### 4.3.4 SystÃ¨me de Scoring de Confiance (Nouveau)

**Fichier** : `ingest/models.py` (ajout de champs)

```python
class ImportationEnCours(models.Model):
    # ... champs existants ...

    # NOUVEAUX CHAMPS
    score_ocr = models.FloatField(null=True, blank=True)  # QualitÃ© JSON (0-100)
    score_espece = models.FloatField(null=True, blank=True)  # Score auto-match
    score_confiance_global = models.FloatField(null=True, blank=True)  # Moyenne pondÃ©rÃ©e

    def calculer_score_confiance(self):
        """
        Calcule un score de confiance global
        score_ocr : 40% (qualitÃ© JSON)
        score_espece : 60% (matching espÃ¨ce)
        """
        if not self.score_ocr or not self.score_espece:
            return None

        score = (self.score_ocr * 0.4) + (self.score_espece * 0.6)
        self.score_confiance_global = round(score, 1)
        self.save()
        return score
```

**Calcul score OCR** :

```python
def calculer_score_ocr(json_data):
    """
    Ã‰value la qualitÃ© du JSON OCR
    - Champs obligatoires remplis : +10 points chacun
    - Pas d'erreurs de validation : +30 points
    - Dates cohÃ©rentes : +10 points
    - Nombres valides : +10 points
    """
    score = 0

    # Champs obligatoires (6 Ã— 10 = 60 points)
    required_fields = [
        ('informations_generales', 'espece'),
        ('informations_generales', 'observateur'),
        ('informations_generales', 'annee'),
        ('localisation', 'commune'),
        ('tableau_donnees', None),  # Au moins une observation
        ('nid', 'nid')
    ]

    for section, field in required_fields:
        if section in json_data:
            if field is None:
                if json_data[section]:
                    score += 10
            elif field in json_data[section] and json_data[section][field]:
                score += 10

    # Pas d'erreurs de validation (+30 points)
    erreurs = validate_json_structure(json_data)
    if not erreurs:
        score += 30

    # CohÃ©rence des dates (+10 points)
    if 'tableau_donnees' in json_data and json_data['tableau_donnees']:
        dates_valides = all(
            1 <= obs.get('Jour', 0) <= 31 and 1 <= obs.get('Mois', 0) <= 12
            for obs in json_data['tableau_donnees']
        )
        if dates_valides:
            score += 10

    return min(score, 100)  # Cap Ã  100
```

#### 4.3.5 Dashboard de Monitoring (Nouveau)

**Fichier** : `ingest/views/monitoring.py`

```python
@login_required
@user_passes_test(lambda u: u.is_staff)
def dashboard_automatisation(request):
    """
    Dashboard de suivi du pipeline automatisÃ©
    """
    # MÃ©triques globales
    total_transcriptions = TranscriptionBrute.objects.count()
    transcriptions_24h = TranscriptionBrute.objects.filter(
        date_creation__gte=timezone.now() - timedelta(hours=24)
    ).count()

    # MÃ©triques d'importation
    importations_pending = ImportationEnCours.objects.filter(statut='en_attente').count()
    importations_complete_24h = ImportationEnCours.objects.filter(
        statut='complete',
        date_finalisation__gte=timezone.now() - timedelta(hours=24)
    ).count()
    importations_erreur = ImportationEnCours.objects.filter(statut='erreur').count()

    # MÃ©triques d'auto-matching
    especes_auto_validees = EspeceCandidate.objects.filter(
        espece_validee__isnull=False,
        validation_manuelle=False
    ).count()
    especes_validation_manuelle = EspeceCandidate.objects.filter(
        espece_validee__isnull=True
    ).count()

    # Distribution des scores de confiance
    scores_distribution = ImportationEnCours.objects.filter(
        score_confiance_global__isnull=False
    ).aggregate(
        score_moyen=Avg('score_confiance_global'),
        score_min=Min('score_confiance_global'),
        score_max=Max('score_confiance_global')
    )

    # EspÃ¨ces problÃ©matiques (frÃ©quentes mais score faible)
    especes_problematiques = EspeceCandidate.objects.filter(
        score_similarite__lt=70
    ).values('nom_transcrit').annotate(
        count=Count('id')
    ).order_by('-count')[:10]

    # Taux de rÃ©ussite par Ã©tape
    taux_reussite_ocr = (
        (total_transcriptions - TranscriptionOCR.objects.filter(erreur__isnull=False).count())
        / total_transcriptions * 100
        if total_transcriptions > 0 else 0
    )

    taux_finalisation = (
        ImportationEnCours.objects.filter(statut='complete').count()
        / ImportationEnCours.objects.count() * 100
        if ImportationEnCours.objects.count() > 0 else 0
    )

    context = {
        'total_transcriptions': total_transcriptions,
        'transcriptions_24h': transcriptions_24h,
        'importations_pending': importations_pending,
        'importations_complete_24h': importations_complete_24h,
        'importations_erreur': importations_erreur,
        'especes_auto_validees': especes_auto_validees,
        'especes_validation_manuelle': especes_validation_manuelle,
        'scores_distribution': scores_distribution,
        'especes_problematiques': especes_problematiques,
        'taux_reussite_ocr': round(taux_reussite_ocr, 1),
        'taux_finalisation': round(taux_finalisation, 1),
    }

    return render(request, 'ingest/dashboard_automatisation.html', context)
```

---

## 5. StratÃ©gie de Gestion des Erreurs

### 5.1 Typologie des Erreurs

| Type d'Erreur | FrÃ©quence | StratÃ©gie | Action Automatique |
|---------------|-----------|-----------|-------------------|
| **OCR - Timeout API** | 5-10% | Retry 3x avec backoff | Skip si Ã©chec total |
| **OCR - JSON invalide** | 2-5% | Auto-correction | Sauvegarde raw + corrigÃ© |
| **Import - EspÃ¨ce inconnue** | 1-3% | Auto-match ou queue | Validation manuelle si score < 0.7 |
| **Import - Commune inconnue** | 5-10% | Utilise nom brut | Log pour amÃ©lioration gÃ©ocodeur |
| **Finalisation - Contrainte BD** | <1% | Auto-correction logique | Log + ajustement (ex: Å“ufs/poussins) |
| **Finalisation - Transaction fail** | <1% | Rollback + retry | 3 tentatives, puis erreur dÃ©finitive |

### 5.2 Niveaux de CriticitÃ©

#### ğŸŸ¢ Niveau 1 : Auto-RÃ©cupÃ©rable (pas d'intervention)

**Exemples** :
- Timeout API avec retry rÃ©ussi
- JSON corrigÃ© automatiquement
- Commune gÃ©ocodÃ©e au 2e essai
- Contraintes BD auto-corrigÃ©es

**Action** : Log informatif, continue

#### ğŸŸ¡ Niveau 2 : DÃ©gradÃ© (fonctionne mais qualitÃ© rÃ©duite)

**Exemples** :
- OCR Ã©chouÃ© aprÃ¨s 3 retries â†’ image sautÃ©e
- GÃ©ocodage Ã©chouÃ© â†’ utilise nom brut
- Auto-match espÃ¨ce < 0.7 â†’ validation manuelle requise

**Action** : Log warning, marque pour revue, continue

#### ğŸ”´ Niveau 3 : Bloquant (intervention requise)

**Exemples** :
- Taux d'Ã©chec OCR > 20% (problÃ¨me API Gemini)
- Transaction BD Ã©choue 3x de suite (problÃ¨me infrastructure)
- Espace disque plein

**Action** : Alerte email/Slack, arrÃªt du pipeline

### 5.3 Dead Letter Queue (DLQ)

**Pour les erreurs persistantes** :

```python
# ingest/models.py
class ImportationErreur(models.Model):
    """
    File d'attente des erreurs non rÃ©cupÃ©rables
    NÃ©cessite intervention manuelle
    """
    importation = models.ForeignKey(ImportationEnCours, on_delete=models.CASCADE)
    type_erreur = models.CharField(max_length=50, choices=[
        ('espece_invalide', 'EspÃ¨ce non validÃ©e'),
        ('transaction_failed', 'Transaction Ã©chouÃ©e'),
        ('data_corruption', 'DonnÃ©es corrompues'),
        ('constraint_violation', 'Violation de contrainte'),
    ])
    message_erreur = models.TextField()
    tentatives = models.IntegerField(default=0)
    date_derniere_tentative = models.DateTimeField(auto_now=True)
    date_creation = models.DateTimeField(auto_now_add=True)
    resolu = models.BooleanField(default=False)

    class Meta:
        db_table = 'ingest_importation_erreur'
        ordering = ['-date_creation']
```

**Processus de rÃ©cupÃ©ration** :

```python
@shared_task
def retry_failed_importations():
    """
    Cron : toutes les heures
    Retente les importations en erreur (max 3 tentatives)
    """
    erreurs = ImportationErreur.objects.filter(
        resolu=False,
        tentatives__lt=3
    )

    for erreur in erreurs:
        erreur.tentatives += 1
        erreur.save()

        try:
            service = ImportationService()
            success, message = service.finaliser_importation(erreur.importation.id)

            if success:
                erreur.resolu = True
                erreur.save()
                logger.info(f"Erreur {erreur.id} rÃ©solue aprÃ¨s {erreur.tentatives} tentatives")
        except Exception as e:
            logger.error(f"Retry failed for erreur {erreur.id}: {e}")

            # Alerte si 3 tentatives Ã©chouÃ©es
            if erreur.tentatives >= 3:
                send_alert_email(
                    subject=f"Importation {erreur.importation.id} en Ã©chec dÃ©finitif",
                    body=f"Type : {erreur.type_erreur}\nMessage : {erreur.message_erreur}"
                )
```

### 5.4 SystÃ¨me d'Alertes

**Configuration alertes** :

```python
# settings.py
ALERTING_CONFIG = {
    'email': {
        'enabled': True,
        'recipients': ['admin@observation-nids.fr'],
        'thresholds': {
            'ocr_failure_rate': 0.20,  # >20% Ã©chec OCR
            'finalization_failure_rate': 0.10,  # >10% Ã©chec finalisation
            'pending_manual_validation': 50,  # >50 espÃ¨ces en attente
        }
    },
    'slack': {
        'enabled': True,
        'webhook_url': 'https://hooks.slack.com/...',
        'channels': {
            'critical': '#alerts-critical',
            'warning': '#alerts-warning',
            'info': '#pipeline-status'
        }
    }
}
```

**Alertes dÃ©clenchÃ©es** :

| Condition | Canal | Niveau |
|-----------|-------|--------|
| Taux Ã©chec OCR > 20% | Email + Slack | ğŸ”´ Critical |
| Taux Ã©chec finalisation > 10% | Email + Slack | ğŸ”´ Critical |
| > 50 espÃ¨ces en attente validation | Slack | ğŸŸ¡ Warning |
| Pipeline bloquÃ© > 1h | Email + Slack | ğŸ”´ Critical |
| Espace disque < 10% | Email + Slack | ğŸ”´ Critical |
| Import rÃ©ussi (batch) | Slack | ğŸŸ¢ Info |

---

## 6. Feuille de Route d'ImplÃ©mentation

### 6.1 Phase 1 : Automatisation de Base (2-3 semaines)

**Objectif** : Ã‰liminer les clics manuels, conserver validation espÃ¨ces

#### Sprint 1.1 : Watcher et Import Auto (1 semaine)

**TÃ¢ches** :
1. DÃ©velopper `JSONWatcher` ou Cron job `auto_import_new_json`
2. Modifier `ImportationService.importer_fichiers_json()` pour supporter batch
3. Ajouter trigger automatique `extraire_candidats()` aprÃ¨s import
4. Tests unitaires + intÃ©gration

**Livrables** :
- âœ… JSON dÃ©tectÃ©s automatiquement
- âœ… TranscriptionBrute crÃ©Ã©es automatiquement
- âœ… EspÃ¨ces et utilisateurs extraits automatiquement

#### Sprint 1.2 : Auto-Finalisation (1 semaine)

**TÃ¢ches** :
1. DÃ©velopper Celery task `auto_finalize_pending_importations()`
2. Configurer Celery Beat (cron toutes les 10 min)
3. Ajouter gestion d'erreurs robuste avec retry
4. Tests de charge (100, 1000, 10000 fiches)

**Livrables** :
- âœ… Finalisation automatique des ImportationEnCours valides
- âœ… Gestion des erreurs avec retry
- âœ… Performance validÃ©e jusqu'Ã  10k fiches/jour

#### Sprint 1.3 : Monitoring et Alertes (1 semaine)

**TÃ¢ches** :
1. DÃ©velopper `dashboard_automatisation()`
2. CrÃ©er modÃ¨le `ImportationErreur` (DLQ)
3. Configurer alertes email + Slack
4. Documentation utilisateur

**Livrables** :
- âœ… Dashboard temps rÃ©el du pipeline
- âœ… Alertes configurÃ©es
- âœ… DLQ opÃ©rationnelle

**RÃ©sultat Phase 1** :
â†’ Pipeline automatisÃ© SAUF validation espÃ¨ces (reste manuelle)
â†’ CapacitÃ© : ~10 000 fiches/jour

---

### 6.2 Phase 2 : Auto-Matching Intelligent (2-3 semaines)

**Objectif** : RÃ©duire Ã  <5% le besoin de validation manuelle d'espÃ¨ces

#### Sprint 2.1 : Dictionnaire d'Ã‰quivalences (1 semaine)

**TÃ¢ches** :
1. CrÃ©er modÃ¨le `EspeceEquivalence`
2. Migrer validations manuelles existantes vers Ã©quivalences
3. Modifier `_trouver_correspondance_espece()` pour utiliser dictionnaire
4. Interface admin pour gÃ©rer Ã©quivalences

**Livrables** :
- âœ… Exact match via dictionnaire
- âœ… Apprentissage des validations manuelles
- âœ… RÃ©utilisation automatique

#### Sprint 2.2 : AmÃ©lioration Auto-Matching (1 semaine)

**TÃ¢ches** :
1. Abaisser threshold Ã  0.7 (au lieu de 0.8)
2. Ajouter fuzzy matching (Levenshtein distance)
3. GÃ©rer variantes orthographiques ("MÃ©sange" vs "Mesange")
4. Tests avec dataset rÃ©el

**Livrables** :
- âœ… Taux d'auto-match > 95%
- âœ… Faux positifs < 2%

#### Sprint 2.3 : Machine Learning (Optionnel - 1 semaine)

**TÃ¢ches** :
1. EntraÃ®ner modÃ¨le de classification (scikit-learn ou TensorFlow)
2. Features : nom transcrit, contexte (localisation, date)
3. IntÃ©gration dans pipeline
4. Monitoring prÃ©cision

**Livrables** :
- âœ… ModÃ¨le ML opÃ©rationnel (si ROI positif)
- âœ… Taux d'auto-match > 98%

**RÃ©sultat Phase 2** :
â†’ Validation manuelle < 5% des espÃ¨ces
â†’ Pipeline quasi-totalement automatisÃ©

---

### 6.3 Phase 3 : Optimisation et Scaling (1-2 semaines)

**Objectif** : Supporter 50 000+ fiches sans dÃ©gradation

#### Sprint 3.1 : Performance OCR (1 semaine)

**TÃ¢ches** :
1. ParallÃ©lisation accrue (20 workers au lieu de 10)
2. Optimisation rate limiting Gemini
3. Cache Redis pour prompts et configs
4. Monitoring Celery avec Flower

**Livrables** :
- âœ… Throughput OCR doublÃ©
- âœ… Temps traitement 50k images : <24h

#### Sprint 3.2 : Performance Base de DonnÃ©es (1 semaine)

**TÃ¢ches** :
1. Bulk insert pour TranscriptionBrute (500/batch)
2. Bulk create pour Observations (Ã©viter N+1 queries)
3. Index BD optimisÃ©s (fichier_source, statut, date_creation)
4. Connection pooling PostgreSQL

**Livrables** :
- âœ… Finalisation 1000 fiches/min
- âœ… Temps finalisation 50k fiches : <1h

**RÃ©sultat Phase 3** :
â†’ 50 000 fiches traitÃ©es en <30h (OCR + import)
â†’ Performance stable jusqu'Ã  100k fiches

---

### 6.4 Phase 4 : SystÃ¨me de Scoring et Priorisation (1 semaine)

**Objectif** : Prioriser la relecture humaine sur les fiches douteuses

#### Sprint 4.1 : Scoring de Confiance

**TÃ¢ches** :
1. Ajouter champs `score_ocr`, `score_espece`, `score_confiance_global`
2. ImplÃ©menter `calculer_score_ocr()` et `calculer_score_confiance()`
3. Calcul automatique lors de finalisation
4. Interface de tri par score

**Livrables** :
- âœ… Chaque fiche a un score de confiance (0-100)
- âœ… Interface de relecture priorisÃ©e (score < 80 en premier)

**RÃ©sultat Phase 4** :
â†’ Relecture humaine efficace (focus sur 20% de fiches Ã  faible score)
â†’ Validation rapide des 80% haute qualitÃ©

---

### 6.5 Calendrier Global

```
Semaine 1-3   : Phase 1 - Automatisation de Base
                â”œâ”€ S1 : Watcher + Import Auto
                â”œâ”€ S2 : Auto-Finalisation
                â””â”€ S3 : Monitoring + Alertes

Semaine 4-6   : Phase 2 - Auto-Matching Intelligent
                â”œâ”€ S4 : Dictionnaire Ã‰quivalences
                â”œâ”€ S5 : AmÃ©lioration Matching
                â””â”€ S6 : ML (optionnel)

Semaine 7-8   : Phase 3 - Optimisation Scaling
                â”œâ”€ S7 : Performance OCR
                â””â”€ S8 : Performance BD

Semaine 9     : Phase 4 - Scoring et Priorisation

Semaine 10    : Tests de charge, Documentation, DÃ©ploiement
```

**DurÃ©e totale** : 10 semaines (2,5 mois)

**Effort estimÃ©** :
- 1 dÃ©veloppeur full-time : 10 semaines
- OU 2 dÃ©veloppeurs : 5-6 semaines

---

### 6.6 Risques et Mitigation

| Risque | ProbabilitÃ© | Impact | Mitigation |
|--------|-------------|--------|-----------|
| **Gemini API rate limit** | Moyenne | ğŸ”´ Ã‰levÃ© | NÃ©gocier quota Ã©levÃ©, backup avec modÃ¨le local |
| **Faux positifs auto-matching** | Faible | ğŸŸ¡ Moyen | Threshold conservateur 0.7, revue pÃ©riodique |
| **Performance BD dÃ©gradÃ©e** | Faible | ğŸ”´ Ã‰levÃ© | Tests de charge prÃ©alables, scaling horizontal |
| **ComplexitÃ© maintenance** | Moyenne | ğŸŸ¡ Moyen | Documentation exhaustive, monitoring proactif |
| **Bugs en production** | Moyenne | ğŸ”´ Ã‰levÃ© | Tests end-to-end, dÃ©ploiement progressif (10%, 50%, 100%) |

---

## 7. MÃ©triques de SuccÃ¨s

### 7.1 KPIs de Performance

| MÃ©trique | Objectif | Mesure |
|----------|----------|--------|
| **Throughput OCR** | >2000 images/heure | Images traitÃ©es/heure |
| **Taux de rÃ©ussite OCR** | >95% | (Images OK / Images totales) Ã— 100 |
| **Throughput finalisation** | >1000 fiches/heure | Fiches finalisÃ©es/heure |
| **Temps total 50k fiches** | <30 heures | De l'image Ã  la BD |

### 7.2 KPIs de QualitÃ©

| MÃ©trique | Objectif | Mesure |
|----------|----------|--------|
| **Taux auto-matching espÃ¨ces** | >95% | EspÃ¨ces validÃ©es auto / EspÃ¨ces totales |
| **Taux de faux positifs** | <2% | EspÃ¨ces corrigÃ©es manuellement / Auto-validÃ©es |
| **Score confiance moyen** | >85 | Moyenne des scores de confiance |
| **Taux d'erreurs bloquantes** | <1% | Importations en erreur dÃ©finitive / Total |

### 7.3 KPIs d'Automatisation

| MÃ©trique | Objectif | Mesure |
|----------|----------|--------|
| **Taux d'automatisation** | >98% | Fiches sans intervention / Total |
| **Intervention manuelle requise** | <50 espÃ¨ces | EspÃ¨ces Ã  valider manuellement |
| **Temps intervention humaine** | <2 heures | Pour 50k fiches |

---

## 8. Conclusion et Recommandations

### 8.1 RÃ©sumÃ© de l'Approche

**Pipeline Actuel** :
- âŒ 9 Ã©tapes dont 5 nÃ©cessitent une action manuelle
- âŒ Ne passe pas Ã  l'Ã©chelle pour >1000 fiches

**Pipeline ProposÃ©** :
- âœ… EntiÃ¨rement automatisÃ© de l'image Ã  la BD
- âœ… Intervention humaine uniquement POST-import (relecture)
- âœ… CapacitÃ© : 50 000+ fiches sans dÃ©gradation
- âœ… Temps traitement : <30 heures

### 8.2 Avantages de l'Automatisation

1. **ScalabilitÃ©** : Traiter 50 000 fiches aussi facilement que 50
2. **RapiditÃ©** : RÃ©duction du temps de traitement de 90%+
3. **CohÃ©rence** : Ã‰limination des erreurs humaines de saisie
4. **CoÃ»t** : LibÃ©ration du temps humain pour tÃ¢ches Ã  forte valeur (analyse, recherche)
5. **QualitÃ©** : Scoring automatique permet de focaliser sur les cas douteux

### 8.3 Recommandations de DÃ©ploiement

#### DÃ©ploiement Progressif (Blue/Green)

**Phase Pilote** (100 fiches) :
- Tester pipeline complet sur un petit batch
- Comparer qualitÃ© vs processus manuel
- Ajuster seuils et paramÃ¨tres

**Phase Beta** (1000 fiches) :
- Activer pour un sous-ensemble d'utilisateurs
- Monitoring intensif
- Collecte feedback

**Phase Production** (50 000+ fiches) :
- DÃ©ploiement complet
- Monitoring continu
- ItÃ©rations d'amÃ©lioration

#### Infrastructure Requise

**Serveur Application** :
- CPU : 8+ cores (Celery workers)
- RAM : 16 GB+ (cache Redis + workers)
- Stockage : 500 GB+ (images + JSON)

**Base de DonnÃ©es** :
- PostgreSQL 14+
- SSD : 100 GB+
- Connection pool : 50+ connexions

**Celery** :
- Redis : 4 GB RAM
- Workers : 10-20 parallÃ¨les
- Queues : `ocr`, `import`, `finalization`

**APIs Externes** :
- Gemini API : quota Ã©levÃ© (>10k req/jour)
- Google Maps API : quota gÃ©ocodage (si utilisÃ©)

### 8.4 Points de Vigilance

1. **QualitÃ© auto-matching** : Monitorer faux positifs, ajuster threshold si nÃ©cessaire
2. **CoÃ»t API Gemini** : Ã‰valuer coÃ»t pour 50k images, nÃ©gocier tarifs si possible
3. **Charge BD** : PrÃ©voir scaling si >100k fiches (sharding, read replicas)
4. **Maintenance** : PrÃ©voir 10% du temps pour maintenance/amÃ©lioration continue

### 8.5 Ã‰volutions Futures (Post-MVP)

**Machine Learning AvancÃ©** :
- ModÃ¨le de classification espÃ¨ces avec contexte (gÃ©ographique, temporel)
- DÃ©tection d'anomalies (observations incohÃ©rentes)
- PrÃ©diction de qualitÃ© OCR avant finalisation

**Feedback Loop** :
- Apprentissage continu depuis corrections manuelles
- AmÃ©lioration automatique du matching
- Adaptation aux nouvelles espÃ¨ces

**IntÃ©gration API Publique** :
- Webhook pour notifications temps rÃ©el
- API REST pour dÃ©clenchement programmatique
- Export automatique vers plateformes externes (INPN, eBird)

---

## 9. Annexes

### 9.1 Fichiers ClÃ©s Ã  Modifier

| Fichier | Modifications | ComplexitÃ© |
|---------|---------------|-----------|
| `pilot/tasks.py` | Ajout auto-trigger OCR | ğŸŸ¢ Faible |
| `ingest/tasks.py` | CrÃ©ation tasks Celery auto | ğŸŸ¡ Moyenne |
| `ingest/importation_service.py` | AmÃ©lioration auto-matching | ğŸŸ¡ Moyenne |
| `ingest/models.py` | Nouveaux modÃ¨les (Ã‰quivalence, Erreur) | ğŸŸ¡ Moyenne |
| `ingest/views/monitoring.py` | Nouveau dashboard | ğŸŸ¢ Faible |
| `settings.py` | Config Celery Beat, alertes | ğŸŸ¢ Faible |

### 9.2 DÃ©pendances Externes

**Nouvelles librairies Python** :
```
# requirements.txt
watchdog==3.0.0  # Filesystem watcher
celery[redis]==5.3.0  # DÃ©jÃ  prÃ©sent
flower==2.0.1  # Monitoring Celery
scikit-learn==1.3.0  # ML (optionnel phase 2)
python-Levenshtein==0.21.0  # Fuzzy matching
```

**Services Externes** :
- Redis (dÃ©jÃ  prÃ©sent pour Celery)
- Slack webhook (optionnel, pour alertes)
- Service email (dÃ©jÃ  prÃ©sent Django)

### 9.3 Commandes Utiles

**Lancer le pipeline automatisÃ©** :
```bash
# DÃ©marrer workers Celery
celery -A observations_nids worker -l info -Q ocr,import,finalization -c 20

# DÃ©marrer Celery Beat (cron tasks)
celery -A observations_nids beat -l info

# Monitoring avec Flower
celery -A observations_nids flower

# Watcher filesystem (si utilisÃ©)
python manage.py run_json_watcher
```

**Monitoring en temps rÃ©el** :
```bash
# Logs Celery
tail -f logs/celery.log

# Dashboard web
http://localhost:5555  # Flower

# Dashboard automatisation
http://localhost:8000/ingest/dashboard/
```

---

**Document crÃ©Ã© le** : 25 dÃ©cembre 2025
**Version** : 1.0
**Auteur** : Analyse automatisÃ©e du systÃ¨me de transcription
**Contact** : Pour questions ou ajustements, se rÃ©fÃ©rer Ã  ce document lors de la phase de rÃ©alisation

---

*Ce document est conÃ§u pour Ãªtre utilisÃ© comme rÃ©fÃ©rence lors de l'implÃ©mentation. Chaque phase peut Ãªtre rÃ©alisÃ©e indÃ©pendamment, permettant un dÃ©ploiement progressif et itÃ©ratif.*
