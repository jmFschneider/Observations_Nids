# pilot/tasks.py
"""
T√¢ches Celery sp√©cifiques pour l'app pilot (optimisation OCR).
Ces t√¢ches seront supprim√©es avec l'app une fois les tests termin√©s.
"""

import copy
import json
import logging
import os
import threading
import time
from functools import wraps

import google.generativeai as genai
from celery import shared_task
from celery.result import AsyncResult
from django.conf import settings
from django.utils import timezone
from PIL import Image

from observations.json_rep.json_sanitizer import corriger_json, validate_json_structure
from observations.models import FicheObservation
from pilot.models import TranscriptionOCR

logger = logging.getLogger('pilot')


# ========================================
# UTILITAIRES DE ROBUSTESSE API
# ========================================


def retry_with_backoff(max_retries=3, initial_delay=2, max_delay=16):
    """
    D√©corateur pour retry avec exponential backoff.

    D√©lais progressifs : 2s ‚Üí 4s ‚Üí 8s ‚Üí 16s (max)

    Args:
        max_retries: Nombre maximum de tentatives (d√©faut: 3)
        initial_delay: D√©lai initial en secondes (d√©faut: 2)
        max_delay: D√©lai maximum en secondes (d√©faut: 16)

    Returns:
        D√©corateur de fonction

    Example:
        @retry_with_backoff(max_retries=3)
        def call_api():
            # Code qui peut √©chouer
    """

    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            delay = initial_delay
            last_error: Exception | None = None

            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_error = e
                    if attempt < max_retries - 1:
                        logger.warning(
                            f"‚ö†Ô∏è Tentative {attempt + 1}/{max_retries} √©chou√©e pour {func.__name__}: {str(e)}. "
                            f"Retry dans {delay}s..."
                        )
                        time.sleep(delay)
                        delay = min(delay * 2, max_delay)  # Exponential backoff
                    else:
                        logger.error(
                            f"‚ùå Toutes les tentatives √©chou√©es pour {func.__name__} apr√®s {max_retries} essais"
                        )

            # last_error ne peut pas √™tre None ici car on sort de la boucle seulement apr√®s une exception
            if last_error is None:
                raise RuntimeError(f"{func.__name__} a √©chou√© sans exception")
            raise last_error

        return wrapper

    return decorator


@retry_with_backoff(max_retries=3, initial_delay=2)
def call_gemini_api_with_timeout(model, prompt, image_path, timeout=120):
    """
    Appel API Gemini avec timeout et retry automatique.

    Args:
        model: Mod√®le Gemini initialis√©
        prompt: Texte du prompt
        image_path: Chemin vers l'image
        timeout: Timeout en secondes (d√©faut: 120s = 2 minutes)

    Returns:
        Texte de la r√©ponse Gemini (nettoy√© UTF-8)

    Raises:
        TimeoutError: Si l'appel d√©passe le timeout
        Exception: Autres erreurs API
    """
    result: list[str | None] = [None]
    exception: list[Exception | None] = [None]

    def api_call():
        """Fonction interne pour l'appel API thread√©"""
        try:
            image = Image.open(image_path)
            try:
                response = model.generate_content([prompt, image])
                result[0] = response.text.encode('utf-8').decode('utf-8')
            finally:
                image.close()  # Lib√©rer la m√©moire
        except Exception as e:
            exception[0] = e

    # Lancer l'appel API dans un thread avec timeout
    thread = threading.Thread(target=api_call)
    thread.daemon = True
    thread.start()
    thread.join(timeout=timeout)

    # V√©rifier le r√©sultat
    if thread.is_alive():
        logger.error(f"‚è±Ô∏è Timeout d√©pass√© ({timeout}s) pour l'appel API")
        raise TimeoutError(f"API call exceeded {timeout}s timeout")

    if exception[0]:
        raise exception[0]

    if result[0] is None:
        raise ValueError("API call returned None")

    return result[0]


class RateLimiter:
    """
    Gestionnaire de rate limiting pour √©viter de d√©passer les quotas API.

    Google Gemini API a une limite de ~60 requ√™tes par minute.
    """

    def __init__(self, requests_per_minute=60):
        """
        Args:
            requests_per_minute: Nombre maximum de requ√™tes par minute (d√©faut: 60)
        """
        self.requests_per_minute = requests_per_minute
        self.min_delay = 60.0 / requests_per_minute  # D√©lai minimum entre requ√™tes
        self.last_request_time = 0.0

    def wait_if_needed(self):
        """
        Attend si n√©cessaire pour respecter le rate limit.

        Cette m√©thode bloque l'ex√©cution si le d√©lai minimum n'est pas √©coul√©
        depuis la derni√®re requ√™te.
        """
        now = time.time()
        elapsed = now - self.last_request_time

        if elapsed < self.min_delay:
            delay = self.min_delay - elapsed
            logger.debug(f"‚è±Ô∏è Rate limit: attente de {delay:.2f}s")
            time.sleep(delay)

        self.last_request_time = time.time()


# ========================================
# UTILITAIRES M√âTIER
# ========================================


def _extraire_nom_base_fichier(chemin_image: str) -> str:
    """
    Extrait le nom de base d'un fichier image (sans extension et sans suffixes _optimisee, _brute, etc.)

    Exemples:
        "fiche_123_optimisee.jpg" -> "fiche_123"
        "observation_456.jpg" -> "observation_456"
    """
    nom_fichier = os.path.splitext(os.path.basename(chemin_image))[0]

    # Retirer les suffixes courants (_optimisee, _brute, _result, etc.)
    suffixes_a_retirer = ['_optimisee', '_brute', '_result', '_raw', '_traitement']
    for suffixe in suffixes_a_retirer:
        if nom_fichier.endswith(suffixe):
            nom_fichier = nom_fichier[: -len(suffixe)]

    return nom_fichier


def _trouver_fiche_correspondante(nom_base_image: str) -> FicheObservation | None:
    """
    Trouve la FicheObservation correspondant √† un nom de fichier image.

    Args:
        nom_base_image: Nom de base du fichier (ex: "fiche_123")

    Returns:
        FicheObservation trouv√©e ou None si non trouv√©e ou ambigu√´
    """
    # Rechercher dans chemin_image
    fiches = FicheObservation.objects.filter(chemin_image__icontains=nom_base_image)

    if fiches.count() == 1:
        return fiches.first()
    elif fiches.count() > 1:
        logger.warning(
            f"Plusieurs fiches trouv√©es pour '{nom_base_image}': {fiches.count()} r√©sultats. "
            "Correspondance ambigu√´, aucune fiche ne sera li√©e."
        )
        return None
    else:
        logger.warning(f"Aucune fiche trouv√©e pour '{nom_base_image}'")
        return None


def _determiner_type_image(chemin_relatif: str) -> str:
    """
    D√©termine le type d'image √† partir du chemin relatif.

    Args:
        chemin_relatif: Chemin relatif du r√©pertoire (ex: "Ancienne_fiche/Sans_traitement")

    Returns:
        'brute' ou 'optimisee'
    """
    if 'Sans_traitement' in chemin_relatif or 'sans_traitement' in chemin_relatif.lower():
        return 'brute'
    else:
        # Traitement_1, Traitement_2, etc. sont consid√©r√©s comme optimis√©s
        return 'optimisee'


def _determiner_type_fiche_et_traitement(chemin_relatif: str) -> tuple[str, str]:
    """
    Extrait le type de fiche et le type de traitement du chemin.

    Args:
        chemin_relatif: Chemin relatif (ex: "Ancienne_fiche/Traitement_1")

    Returns:
        Tuple (type_fiche, type_traitement)
        Ex: ("Ancienne_fiche", "Traitement_1")
    """
    parts = chemin_relatif.split(os.sep)

    type_fiche = "Inconnu"
    type_traitement = "Inconnu"

    # Le type de fiche est g√©n√©ralement le premier niveau
    if len(parts) >= 1:
        type_fiche = parts[0]

    # Le type de traitement est g√©n√©ralement le second niveau
    if len(parts) >= 2:
        type_traitement = parts[1]

    return type_fiche, type_traitement


def _charger_prompt_selon_type_fiche(chemin_relatif: str) -> str:
    """
    Charge le bon prompt selon le type de fiche d√©tect√© dans le chemin.

    R√®gle de d√©tection :
    - Si le chemin contient "ancien" ou "Ancien" ‚Üí prompt anciennes fiches
    - Sinon ‚Üí prompt standard

    Args:
        chemin_relatif: Chemin du r√©pertoire (ex: "Ancienne_fiche/Traitement_1")

    Returns:
        Contenu du prompt en string

    Raises:
        ValueError: Si le prompt n'est pas trouv√©

    Example:
        >>> _charger_prompt_selon_type_fiche("Ancienne_fiche/Sans_traitement")
        # Retourne le contenu de prompt_gemini_transcription_Ancienne_Fiche.txt
    """
    type_fiche, _ = _determiner_type_fiche_et_traitement(chemin_relatif)

    # D√©terminer quel prompt utiliser (insensible √† la casse)
    # Recherche "ancien" n'importe o√π dans le chemin complet
    if 'ancien' in chemin_relatif.lower():
        prompt_filename = 'prompt_gemini_transcription_Ancienne_Fiche.txt'
        logger.info(f"üìÑ Prompt ANCIENNES FICHES s√©lectionn√© pour: {chemin_relatif}")
    else:
        prompt_filename = 'prompt_gemini_transcription.txt'
        logger.info(f"üìÑ Prompt STANDARD s√©lectionn√© pour: {chemin_relatif}")

    prompt_path = os.path.join(settings.BASE_DIR, 'observations', 'json_rep', prompt_filename)

    try:
        with open(prompt_path, encoding='utf-8') as f:
            prompt_content = f.read()
            logger.debug(f"‚úì Prompt charg√©: {prompt_filename} ({len(prompt_content)} chars)")
            return prompt_content
    except FileNotFoundError as e:
        logger.error(f"‚ùå Prompt introuvable: {prompt_path}")
        raise ValueError(f"Prompt {prompt_filename} non trouv√© dans observations/json_rep/") from e


def _log_progress(task_self, message, level='info', details=None):
    """
    Ajoute un message au log de progression visible en temps r√©el.

    Args:
        task_self: Instance de la t√¢che Celery (self)
        message: Message √† logger
        level: Niveau du log ('info', 'success', 'warning', 'error')
        details: D√©tails optionnels (dict)
    """
    timestamp = timezone.now().strftime('%H:%M:%S')

    # Construire l'entr√©e de log
    log_entry = {
        'timestamp': timestamp,
        'message': message,
        'level': level,
    }
    if details:
        log_entry['details'] = details

    # R√©cup√©rer la meta actuelle de la t√¢che via AsyncResult
    try:
        result = AsyncResult(task_self.request.id)
        current_meta = result.info if result.info and isinstance(result.info, dict) else {}
    except Exception:
        current_meta = {}

    # Ajouter le nouveau log
    logs = current_meta.get('logs', [])
    logs.append(log_entry)

    # Limiter √† 150 derni√®res entr√©es pour ne pas surcharger Redis
    if len(logs) > 150:
        logs = logs[-150:]

    # Mettre √† jour la meta avec les logs (pr√©serve les autres champs comme processed, total, etc.)
    current_meta['logs'] = logs

    # Utiliser update_state pour mettre √† jour Redis
    task_self.update_state(state='PROGRESS', meta=current_meta)

    # Logger aussi dans les logs serveur pour historique
    log_method = getattr(logger, level if level in ['info', 'warning', 'error'] else 'info')
    log_method(f"[{timestamp}] {message}")


@shared_task(bind=True, name='pilot.process_batch_transcription')
def process_batch_transcription_task(self, directories: list[dict], modeles_ocr: list[str]):
    """
    T√¢che Celery pour traiter plusieurs r√©pertoires en batch avec plusieurs mod√®les OCR.

    Cette t√¢che est sp√©cifique √† l'app pilot pour l'√©valuation OCR.
    Elle traite chaque r√©pertoire avec chaque mod√®le s√©lectionn√© (ex√©cution s√©quentielle),
    g√©n√®re les transcriptions JSON, et cr√©e automatiquement les entr√©es TranscriptionOCR
    pour comparaison avec la v√©rit√© terrain.

    **Mode pilote uniquement** : Cette t√¢che g√©n√®re les fichiers JSON pour √©valuation.
    L'importation en base de donn√©es se fait depuis l'app observations.

    Args:
        directories: Liste de dictionnaires avec 'path' (chemin relatif) et 'name' (nom du r√©pertoire)
        modeles_ocr: Liste des noms de mod√®les OCR √† utiliser (ex: ["gemini_3_flash", "gemini_3_pro"])

    Returns:
        dict: R√©sultats globaux du traitement batch
    """
    media_root = str(settings.MEDIA_ROOT)

    # Mapper les noms de mod√®les vers les identifiants Gemini API
    modeles_mapping = {
        'gemini_3_flash': 'gemini-3-flash-preview',
        'gemini_3_pro': 'gemini-3-pro-preview',
        'gemini_2.5_pro': 'gemini-2.5-pro',
        'gemini_2.5_flash_lite': 'gemini-2.5-flash-lite',
    }

    logger.info(
        f"D√©but du traitement batch: {len(directories)} r√©pertoire(s), "
        f"{len(modeles_ocr)} mod√®le(s) ({', '.join(modeles_ocr)})"
    )

    # Configuration API Gemini
    api_key = getattr(settings, 'GEMINI_API_KEY', os.environ.get("GEMINI_API_KEY"))
    if not api_key:
        logger.error("Cl√© API Gemini non configur√©e")
        return {'status': 'ERROR', 'error': "Cl√© API Gemini non configur√©e"}

    genai.configure(api_key=api_key)

    # Log de d√©marrage
    _log_progress(
        self,
        f"üöÄ D√©marrage du traitement batch: {len(directories)} r√©pertoire(s), {len(modeles_ocr)} mod√®le(s)",
        'info',
    )

    # R√©sultats globaux
    all_results = []
    total_success = 0
    total_errors = 0
    start_time_global = time.time()

    # Calculer le nombre total d'images par r√©pertoire (pour la progression)
    images_par_repertoire = 0
    for dir_info in directories:
        dir_path = os.path.join(media_root, dir_info['path'])
        if os.path.exists(dir_path):
            images = [
                f
                for f in os.listdir(dir_path)
                if os.path.isfile(os.path.join(dir_path, f))
                and f.lower().endswith(('.jpg', '.jpeg'))
            ]
            images_par_repertoire += len(images)

    # Total d'images = images par r√©pertoire √ó nombre de mod√®les
    total_images = images_par_repertoire * len(modeles_ocr)

    if images_par_repertoire == 0:
        logger.warning("Aucune image trouv√©e dans les r√©pertoires s√©lectionn√©s")
        return {
            'status': 'SUCCESS',
            'results': [],
            'modeles_ocr': modeles_ocr,
            'total_directories': len(directories),
            'total_images': 0,
            'total_success': 0,
            'total_errors': 0,
            'duration': 0,
        }

    processed_count = 0

    # Traiter avec chaque mod√®le OCR
    for modele_index, modele_ocr in enumerate(modeles_ocr):
        modele_api = modeles_mapping.get(modele_ocr, 'gemini-3-flash-preview')

        logger.info(
            f"‚ïê‚ïê‚ïê Traitement avec mod√®le {modele_index + 1}/{len(modeles_ocr)}: "
            f"{modele_ocr} ({modele_api}) ‚ïê‚ïê‚ïê"
        )

        # Log du d√©marrage du mod√®le
        _log_progress(
            self,
            f"‚ïê‚ïê‚ïê Mod√®le {modele_index + 1}/{len(modeles_ocr)}: {modele_ocr} ({modele_api}) ‚ïê‚ïê‚ïê",
            'info',
        )

        # Initialiser le mod√®le Gemini
        model = genai.GenerativeModel(modele_api)

        # Cr√©er le rate limiter pour ce mod√®le (60 req/min = limite Google Gemini)
        rate_limiter = RateLimiter(requests_per_minute=60)

        # Traiter chaque r√©pertoire avec ce mod√®le
        for dir_index, dir_info in enumerate(directories):
            dir_path_relatif = dir_info['path']
            dir_path_complet = os.path.join(media_root, dir_path_relatif)

            logger.info(
                f"  ‚Üí R√©pertoire {dir_index + 1}/{len(directories)}: {dir_path_relatif} "
                f"(mod√®le: {modele_ocr})"
            )

            # Log du d√©marrage du r√©pertoire
            _log_progress(
                self, f"‚Üí R√©pertoire {dir_index + 1}/{len(directories)}: {dir_path_relatif}", 'info'
            )

            if not os.path.exists(dir_path_complet):
                logger.error(f"Le r√©pertoire {dir_path_complet} n'existe pas")
                all_results.append(
                    {
                        'directory': dir_path_relatif,
                        'modele_ocr': modele_ocr,
                        'status': 'error',
                        'error': "R√©pertoire inexistant",
                    }
                )
                continue

            # Cr√©er le r√©pertoire de r√©sultats (inclure le mod√®le dans le chemin)
            results_dir = os.path.join(
                media_root, 'transcription_results', dir_path_relatif, modele_ocr
            )
            os.makedirs(results_dir, exist_ok=True)

            # R√©cup√©rer les m√©tadonn√©es du r√©pertoire
            type_fiche, type_traitement = _determiner_type_fiche_et_traitement(dir_path_relatif)
            type_image = _determiner_type_image(dir_path_relatif)

            # Charger le prompt appropri√© selon le type de fiche
            try:
                prompt = _charger_prompt_selon_type_fiche(dir_path_relatif)
                # Log de s√©lection du prompt
                prompt_type = "ANCIENNES FICHES" if 'ancien' in type_fiche.lower() else "STANDARD"
                _log_progress(
                    self, f"üìÑ Prompt {prompt_type} s√©lectionn√© pour {type_fiche}", 'success'
                )
            except ValueError as e:
                logger.error(f"‚ùå Erreur chargement prompt pour {dir_path_relatif}: {e}")
                _log_progress(self, f"‚ùå Erreur chargement prompt: {str(e)}", 'error')
                all_results.append(
                    {
                        'directory': dir_path_relatif,
                        'modele_ocr': modele_ocr,
                        'status': 'error',
                        'error': f"Prompt introuvable: {str(e)}",
                        'files': [],
                    }
                )
                continue  # Passer au r√©pertoire suivant

            # R√©cup√©rer les fichiers images
            image_files = [
                f
                for f in os.listdir(dir_path_complet)
                if os.path.isfile(os.path.join(dir_path_complet, f))
                and f.lower().endswith(('.jpg', '.jpeg'))
            ]

            if not image_files:
                logger.warning(f"Aucune image dans {dir_path_relatif}")
                all_results.append(
                    {
                        'directory': dir_path_relatif,
                        'modele_ocr': modele_ocr,
                        'status': 'success',
                        'images': [],
                    }
                )
                continue

            dir_results = []

            # Traiter chaque image
            for img_file in image_files:
                file_start = time.time()
                img_path_complet = os.path.join(dir_path_complet, img_file)
                img_path_relatif = os.path.join(dir_path_relatif, img_file)

                logger.info(
                    f"Traitement de {img_path_relatif} ({processed_count + 1}/{total_images})"
                )

                # Log du d√©but du traitement
                _log_progress(
                    self, f"üñºÔ∏è Traitement {img_file} ({processed_count + 1}/{total_images})", 'info'
                )

                # Mise √† jour de la progression
                self.update_state(
                    state='PROGRESS',
                    meta={
                        'processed': processed_count,
                        'total': total_images,
                        'current_file': img_file,
                        'current_directory': dir_path_relatif,
                        'current_model': modele_ocr,
                        'percent': int((processed_count / total_images) * 100),
                    },
                )

                try:
                    # Respecter le rate limiting (1 req/sec max)
                    rate_limiter.wait_if_needed()

                    # Traitement de l'image avec le mod√®le OCR (avec retry, timeout)
                    api_start = time.time()
                    text_response = call_gemini_api_with_timeout(
                        model=model,
                        prompt=prompt,
                        image_path=img_path_complet,
                        timeout=120,  # 2 minutes max par image
                    )
                    api_duration = time.time() - api_start

                    # Log de succ√®s de l'API
                    _log_progress(self, f"‚úì API r√©ussie ({api_duration:.1f}s)", 'success')

                    # Nettoyage des marqueurs markdown
                    if text_response.startswith("```json"):
                        text_response = text_response[7:].strip()
                        if text_response.endswith("```"):
                            text_response = text_response[:-3].strip()

                    # Parsing JSON
                    try:
                        json_data = json.loads(text_response)
                        logger.debug(f"JSON correctement pars√© pour {img_file}")
                    except json.JSONDecodeError as e:
                        logger.error(f"Erreur de d√©codage JSON pour {img_file}: {str(e)}")
                        raise ValueError(f"R√©ponse non JSON: {text_response[:100]}...") from e

                    if json_data:
                        # Validation et correction
                        erreurs = validate_json_structure(json_data)
                        if erreurs:
                            logger.warning(
                                f"Structure JSON invalide pour {img_file}, correction en cours. Erreurs: {erreurs}"
                            )
                            _log_progress(self, "‚ö†Ô∏è JSON invalide, correction en cours", 'warning')
                            json_data_raw = copy.deepcopy(json_data)
                            json_data = corriger_json(json_data_raw)

                            # Enregistrement du JSON brut
                            raw_path = os.path.join(
                                results_dir, f"{os.path.splitext(img_file)[0]}_raw.json"
                            )
                            with open(raw_path, 'w', encoding='utf-8') as f:
                                json.dump(json_data_raw, f, indent=2, ensure_ascii=False)

                            _log_progress(
                                self, "‚úì JSON corrig√© et sauvegard√© (raw + corrig√©)", 'success'
                            )
                        else:
                            _log_progress(self, "‚úì JSON valide", 'success')

                        # Enregistrement du JSON final
                        json_filename = f"{os.path.splitext(img_file)[0]}_result.json"
                        json_path_complet = os.path.join(results_dir, json_filename)
                        json_path_relatif = os.path.join(
                            'transcription_results', dir_path_relatif, modele_ocr, json_filename
                        )

                        with open(json_path_complet, 'w', encoding='utf-8') as f:
                            json.dump(json_data, f, indent=2, ensure_ascii=False)

                        _log_progress(self, f"üíæ JSON sauvegard√©: {json_filename}", 'success')

                        duration = round(time.time() - file_start, 2)
                        logger.info(f"Transcription r√©ussie pour {img_file}, dur√©e: {duration}s")

                        # Cr√©er l'entr√©e TranscriptionOCR (mode pilote: JSON uniquement)
                        nom_base = _extraire_nom_base_fichier(img_path_relatif)

                        # Chercher une fiche correspondante pour la lier (utile pour l'√©valuation)
                        fiche = _trouver_fiche_correspondante(nom_base)

                        transcription_ocr = TranscriptionOCR.objects.create(
                            fiche=fiche,  # Peut √™tre None si pas de correspondance
                            chemin_json=json_path_relatif,
                            chemin_image=img_path_relatif,
                            type_image=type_image,
                            modele_ocr=modele_ocr,
                            temps_traitement_secondes=duration,
                            statut_evaluation='non_evaluee',
                        )

                        logger.info(
                            f"TranscriptionOCR cr√©√©e (ID: {transcription_ocr.id}) pour {img_file}"
                            + (f" - Li√©e √† fiche {fiche.pk}" if fiche else " - Aucune fiche li√©e")
                        )

                        # Log de cr√©ation de TranscriptionOCR
                        fiche_info = f" (li√©e √† fiche {fiche.pk})" if fiche else " (sans fiche)"
                        _log_progress(
                            self,
                            f"‚úì TranscriptionOCR cr√©√©e (ID: {transcription_ocr.id}){fiche_info}",
                            'success',
                        )

                        file_result = {
                            'filename': img_file,
                            'status': 'success',
                            'json_path': json_path_relatif,
                            'duration': duration,
                            'transcription_id': transcription_ocr.id,
                            'fiche_linked': fiche.pk if fiche else None,
                        }
                        total_success += 1
                    else:
                        raise ValueError("Donn√©es JSON vides ou invalides")

                except TimeoutError as e:
                    logger.error(f"‚è±Ô∏è Timeout pour {img_file} apr√®s 120s (et {3} retries): {str(e)}")
                    _log_progress(
                        self, f"‚ùå Timeout apr√®s 120s (3 retries) pour {img_file}", 'error'
                    )
                    file_result = {
                        'filename': img_file,
                        'status': 'timeout',
                        'error': "Timeout apr√®s 120s (3 retries)",
                        'duration': round(time.time() - file_start, 2),
                    }
                    total_errors += 1

                except Exception as e:
                    logger.error(f"‚ùå Erreur lors du traitement de {img_file}: {str(e)}")
                    _log_progress(self, f"‚ùå Erreur: {str(e)[:100]}", 'error')
                    file_result = {
                        'filename': img_file,
                        'status': 'error',
                        'error': str(e),
                        'duration': round(time.time() - file_start, 2),
                    }
                    total_errors += 1

                dir_results.append(file_result)
                processed_count += 1

            all_results.append(
                {
                    'directory': dir_path_relatif,
                    'modele_ocr': modele_ocr,
                    'status': 'success',
                    'images': dir_results,
                    'type_fiche': type_fiche,
                    'type_traitement': type_traitement,
                    'type_image': type_image,
                }
            )

    # R√©sultats finaux
    duration_total = round(time.time() - start_time_global, 2)

    final_result = {
        'status': 'SUCCESS',
        'results': all_results,
        'modeles_ocr': modeles_ocr,
        'total_directories': len(directories),
        'total_models': len(modeles_ocr),
        'total_images': total_images,
        'total_success': total_success,
        'total_errors': total_errors,
        'success_rate': round((total_success / total_images) * 100, 1) if total_images > 0 else 0,
        'duration': duration_total,
    }

    logger.info("‚ïê‚ïê‚ïê Traitement batch termin√© ‚ïê‚ïê‚ïê")
    logger.info(
        f"  {len(modeles_ocr)} mod√®le(s) √ó {len(directories)} r√©pertoire(s) = {total_images} images"
    )
    logger.info(
        f"  {total_success} succ√®s / {total_errors} erreurs ({final_result['success_rate']}%)"
    )
    logger.info(f"  Dur√©e totale: {duration_total}s")

    return final_result
